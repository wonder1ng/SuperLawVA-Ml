# contract_service.py
"""
Description: ê³„ì•½ì„œ íŠ¹ì•½ì‚¬í•­ ìƒì„± í•µì‹¬ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ë° ë²¡í„°DBÂ·LLM ì—°ë™ êµ¬í˜„
Author: ooheunsu
Date: 2025-06-16
Requirements: python-dotenv, langchain-anthropic, langchain-openai, langchain-chroma, pydantic, asyncio, json, re, os
ì‹¤ì œ ë©”íƒ€ë°ì´í„° case_id ì‚¬ìš©ìœ¼ë¡œ ìˆ˜ì •
"""

import asyncio
import json
import re
from typing import Any, Dict, List, Set

from config import (ANTHROPIC_API_KEY, CASE_COLLECTION_NAME,
                    CHROMA_CASE_DB_PATH, CHROMA_LAW_DB_PATH,
                    LAW_COLLECTION_NAME, MAX_DISTANCE, OPENAI_API_KEY,
                    VECTOR_SEARCH_K)
from langchain.output_parsers import PydanticOutputParser
from langchain.prompts import ChatPromptTemplate
from langchain.schema import HumanMessage, SystemMessage
from langchain.schema.output_parser import BaseOutputParser
from langchain.schema.runnable import RunnablePassthrough
from langchain_anthropic import ChatAnthropic
from langchain_community.embeddings import OpenAIEmbeddings
from langchain_community.vectorstores import Chroma
from src.vectordb.loaders.load_case_db import load_case_vectorstore
from src.vectordb.loaders.load_law_db import load_law_vectorstore

from .schema.terms_schema import (CaseBasis, ContractInput, ContractOutput,
                                  LegalBasis, RecommendedAgreement)

# import os
# from dotenv import load_dotenv




# load_dotenv()


class CustomJSONOutputParser(BaseOutputParser[ContractOutput]):
    """JSON ë§ˆí¬ë‹¤ìš´ ë¸”ë¡ì„ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” ì»¤ìŠ¤í…€ íŒŒì„œ"""

    def parse(self, text: str) -> ContractOutput:
        """JSON í…ìŠ¤íŠ¸ë¥¼ íŒŒì‹±í•˜ì—¬ ContractOutput ê°ì²´ë¡œ ë³€í™˜"""
        try:
            print(f"ğŸ” íŒŒì‹±í•  ì›ë³¸ í…ìŠ¤íŠ¸ (ì²˜ìŒ 200ì): {text[:200]}...")

            # 1. ë§ˆí¬ë‹¤ìš´ JSON ë¸”ë¡ ì œê±°
            json_pattern = r"```json\s*(.*?)\s*```"
            match = re.search(json_pattern, text, re.DOTALL)

            if match:
                json_text = match.group(1)
                print("âœ… ë§ˆí¬ë‹¤ìš´ JSON ë¸”ë¡ ë°œê²¬ ë° ì¶”ì¶œ")
            else:
                # ë§ˆí¬ë‹¤ìš´ ë¸”ë¡ì´ ì—†ìœ¼ë©´ ì „ì²´ í…ìŠ¤íŠ¸ì—ì„œ JSON ì¶”ì¶œ ì‹œë„
                json_text = text.strip()
                print("âš ï¸ ë§ˆí¬ë‹¤ìš´ ë¸”ë¡ ì—†ìŒ, ì „ì²´ í…ìŠ¤íŠ¸ë¡œ íŒŒì‹± ì‹œë„")

            print(f"ğŸ” ì¶”ì¶œëœ JSON í…ìŠ¤íŠ¸ (ì²˜ìŒ 200ì): {json_text[:200]}...")

            # 2. JSON íŒŒì‹±
            parsed_data = json.loads(json_text)
            print("âœ… JSON íŒŒì‹± ì„±ê³µ")

            # 3. law_id íƒ€ì… ë³€í™˜ (ë¬¸ìì—´ â†’ ìˆ«ì)
            if "legal_basis" in parsed_data:
                for legal in parsed_data["legal_basis"]:
                    if "law_id" in legal and legal["law_id"] is not None:
                        original_id = legal["law_id"]
                        # ë¬¸ìì—´ì„ intë¡œ ë³€í™˜ (ì•ì˜ 0ë“¤ ìë™ ì œê±°)
                        try:
                            legal["law_id"] = (
                                int(str(original_id))
                                if str(original_id).isdigit()
                                else None
                            )
                            print(f"ğŸ”„ law_id ë³€í™˜: {original_id} â†’ {legal['law_id']}")
                        except (ValueError, TypeError):
                            legal["law_id"] = None
                            print(f"âš ï¸ law_id ë³€í™˜ ì‹¤íŒ¨: {original_id} â†’ None")

            # 4. case_id íƒ€ì… ë³€í™˜ (ë¬¸ìì—´ â†’ ìˆ«ì)
            if "case_basis" in parsed_data:
                for case in parsed_data["case_basis"]:
                    if "case_id" in case and case["case_id"] is not None:
                        original_id = case["case_id"]
                        # ë¬¸ìì—´ì„ intë¡œ ë³€í™˜ (ì•ì˜ 0ë“¤ ìë™ ì œê±°)
                        try:
                            case["case_id"] = (
                                int(str(original_id))
                                if str(original_id).isdigit()
                                else None
                            )
                            print(f"ğŸ”„ case_id ë³€í™˜: {original_id} â†’ {case['case_id']}")
                        except (ValueError, TypeError):
                            case["case_id"] = None
                            print(f"âš ï¸ case_id ë³€í™˜ ì‹¤íŒ¨: {original_id} â†’ None")

            # 5. ë¶ˆí•„ìš”í•œ í•„ë“œ ì œê±° (created_date ë“±)
            filtered_data = {
                "recommended_agreements": parsed_data.get("recommended_agreements", []),
                "legal_basis": parsed_data.get("legal_basis", []),
                "case_basis": parsed_data.get("case_basis", []),
            }

            print(
                f"ğŸ“Š íŒŒì‹± ê²°ê³¼ - íŠ¹ì•½: {len(filtered_data['recommended_agreements'])}ê°œ, ë²•ë ¹: {len(filtered_data['legal_basis'])}ê°œ, íŒë¡€: {len(filtered_data['case_basis'])}ê°œ"
            )

            # 6. Pydantic ëª¨ë¸ë¡œ ë³€í™˜
            result = ContractOutput(**filtered_data)
            print("âœ… ContractOutput ê°ì²´ ìƒì„± ì„±ê³µ")
            return result

        except json.JSONDecodeError as e:
            print(f"âŒ JSON íŒŒì‹± ì‹¤íŒ¨: {str(e)}")
            print(f"ğŸ“„ ë¬¸ì œê°€ ëœ í…ìŠ¤íŠ¸: {text[:500]}...")
            raise ValueError(f"JSON íŒŒì‹± ì‹¤íŒ¨: {str(e)}")
        except Exception as e:
            print(f"âŒ ì „ì²´ íŒŒì‹± ì‹¤íŒ¨: {str(e)}")
            print(f"ğŸ“„ ì›ë³¸ í…ìŠ¤íŠ¸: {text[:500]}...")
            raise ValueError(f"íŒŒì‹± ì‹¤íŒ¨: {str(e)}")

    def get_format_instructions(self) -> str:
        """ì¶œë ¥ í˜•ì‹ ì§€ì‹œì‚¬í•­"""
        return """
ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš” (ë§ˆí¬ë‹¤ìš´ ë¸”ë¡ ì‚¬ìš© ê¸ˆì§€):

{
  "recommended_agreements": [
    {
      "reason": "íŠ¹ì•½ì‚¬í•­ ì´ìœ ",
      "suggested_revision": "ì œì•ˆí•˜ëŠ” íŠ¹ì•½ ì¡°í•­",
      "negotiation_points": "í˜‘ìƒ í¬ì¸íŠ¸"
    }
  ],
  "legal_basis": [
    {
      "law_id": 1234,
      "law": "ë²•ë ¹ëª… ì œâ—‹ì¡° ì œâ—‹í•­",
      "explanation": "ë²•ë ¹ ì„¤ëª…",
      "content": "ë²•ë ¹ ì›ë¬¸"
    }
  ],
  "case_basis": [
    {
      "case_id": 1243,
      "case": "íŒë¡€ëª…",
      "explanation": "íŒë¡€ ì„¤ëª… (ì„ì°¨ì¸ ê´€ì ì—ì„œ)",
      "link": "íŒë¡€ ë§í¬"
    }
  ]
}

ì¤‘ìš”: 
- ë§ˆí¬ë‹¤ìš´ ```json ë¸”ë¡ì„ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”
- ìˆœìˆ˜ JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”
- law_idëŠ” ë°˜ë“œì‹œ ìˆ«ìë¡œ ì‘ì„±í•˜ì„¸ìš” (ì˜ˆ: 1234)
- case_idëŠ” ë°˜ë“œì‹œ ìˆ«ìë¡œ ì‘ì„±í•˜ì„¸ìš” (ì˜ˆ: 5, 1234 ë“±)
"""


# class VectorDBManager:
#     """ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ê´€ë¦¬ í´ë˜ìŠ¤"""

#     def __init__(self):
#         self.law_db = None
#         self.case_db = None


class VectorDBManager:
    def __init__(self):
        self.law_db = load_law_vectorstore()
        self.case_db = load_case_vectorstore()
        self._initialize_dbs()

    # def _initialize_dbs(self):
    #     """ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”"""
    #     try:
    #         # ì„ë² ë”© ëª¨ë¸ ì„¤ì • (3072 ì°¨ì› ëª¨ë¸ ì‚¬ìš©)
    #         embeddings = OpenAIEmbeddings(model="text-embedding-3-large")

    #         # ë²•ë ¹ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°
    #         law_db_path = os.getenv("CHROMA_LAW_DB_PATH", "./vectordb/chroma_law/chroma_openai_law")
    #         law_collection_name = os.getenv("LAW_COLLECTION_NAME", "law_chunks_openai")

    #         if os.path.exists(law_db_path):
    #             self.law_db = Chroma(
    #                 persist_directory=law_db_path,
    #                 embedding_function=embeddings,
    #                 collection_name=law_collection_name
    #             )
    #             print(f"âœ… ë²•ë ¹ DB ì—°ê²° ì™„ë£Œ: {law_db_path}")
    #             print(f"ğŸ“‹ ë²•ë ¹ ì»¬ë ‰ì…˜ëª…: {law_collection_name}")

    #             # ì»¬ë ‰ì…˜ ì •ë³´ í™•ì¸
    #             try:
    #                 collection_count = self.law_db._collection.count()
    #                 print(f"ğŸ“Š ë²•ë ¹ ë°ì´í„° ê°œìˆ˜: {collection_count}ê°œ")
    #             except Exception as e:
    #                 print(f"âš ï¸ ë²•ë ¹ ì»¬ë ‰ì…˜ ì •ë³´ í™•ì¸ ì‹¤íŒ¨: {e}")
    #         else:
    #             print(f"âš ï¸ ë²•ë ¹ DB ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {law_db_path}")

    #         # íŒë¡€ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°
    #         case_db_path = os.getenv("CHROMA_CASE_DB_PATH", "./vectordb/chroma_case/chroma_openai_case")
    #         case_collection_name = os.getenv("CASE_COLLECTION_NAME", "case_chunks_openai")

    #         if os.path.exists(case_db_path):
    #             self.case_db = Chroma(
    #                 persist_directory=case_db_path,
    #                 embedding_function=embeddings,
    #                 collection_name=case_collection_name
    #             )
    #             print(f"âœ… íŒë¡€ DB ì—°ê²° ì™„ë£Œ: {case_db_path}")
    #             print(f"ğŸ“‹ íŒë¡€ ì»¬ë ‰ì…˜ëª…: {case_collection_name}")

    #             # ì»¬ë ‰ì…˜ ì •ë³´ í™•ì¸
    #             try:
    #                 collection_count = self.case_db._collection.count()
    #                 print(f"ğŸ“Š íŒë¡€ ë°ì´í„° ê°œìˆ˜: {collection_count}ê°œ")
    #             except Exception as e:
    #                 print(f"âš ï¸ íŒë¡€ ì»¬ë ‰ì…˜ ì •ë³´ í™•ì¸ ì‹¤íŒ¨: {e}")
    #         else:
    #             print(f"âš ï¸ íŒë¡€ DB ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {case_db_path}")

    #     except Exception as e:
    #         print(f"âŒ ë²¡í„°DB ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")

    def _initialize_dbs(self):
        """ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”"""
        try:
            # ì„ë² ë”© ëª¨ë¸ ì„¤ì • (3072 ì°¨ì› ëª¨ë¸ ì‚¬ìš©)
            embeddings = OpenAIEmbeddings(
                model="text-embedding-3-large", openai_api_key=OPENAI_API_KEY
            )
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            # ë²•ë ¹ ë²¡í„°ìŠ¤í† ì–´ ë¡œë”©
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            try:
                law_db_path = str(CHROMA_LAW_DB_PATH)
                law_collection_name = LAW_COLLECTION_NAME

                self.law_db = Chroma(
                    persist_directory=law_db_path,
                    embedding_function=embeddings,
                    collection_name=law_collection_name,
                )
                print(f"âœ… ë²•ë ¹ DB ì—°ê²° ì™„ë£Œ: {law_db_path}")
                print(f"ğŸ“‹ ë²•ë ¹ ì»¬ë ‰ì…˜ëª…: {law_collection_name}")
                try:
                    collection_count = self.law_db._collection.count()
                    print(f"ğŸ“Š ë²•ë ¹ ë°ì´í„° ê°œìˆ˜: {collection_count}ê°œ")
                except Exception as e:
                    print(f"âš ï¸ ë²•ë ¹ ì»¬ë ‰ì…˜ ì •ë³´ í™•ì¸ ì‹¤íŒ¨: {e}")
            except Exception as e:
                print(f"âŒ ë²•ë ¹ DB ë¡œë”© ì‹¤íŒ¨: {e}")

            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            # íŒë¡€ ë²¡í„°ìŠ¤í† ì–´ ë¡œë”©
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            try:
                case_db_path = str(CHROMA_CASE_DB_PATH)
                case_collection_name = CASE_COLLECTION_NAME

                self.case_db = Chroma(
                    persist_directory=case_db_path,
                    embedding_function=embeddings,
                    collection_name=case_collection_name,
                )
                print(f"âœ… íŒë¡€ DB ì—°ê²° ì™„ë£Œ: {case_db_path}")
                print(f"ğŸ“‹ íŒë¡€ ì»¬ë ‰ì…˜ëª…: {case_collection_name}")
                try:
                    collection_count = self.case_db._collection.count()
                    print(f"ğŸ“Š íŒë¡€ ë°ì´í„° ê°œìˆ˜: {collection_count}ê°œ")
                except Exception as e:
                    print(f"âš ï¸ íŒë¡€ ì»¬ë ‰ì…˜ ì •ë³´ í™•ì¸ ì‹¤íŒ¨: {e}")
            except Exception as e:
                print(f"âŒ íŒë¡€ DB ë¡œë”© ì‹¤íŒ¨: {e}")

        except Exception as e:
            print(f"âŒ ë²¡í„°DB ì´ˆê¸°í™” ì‹¤íŒ¨ (ì „ì²´ ì—ëŸ¬): {e}")

    def _format_article(self, metadata: Dict) -> str:
        """ì¡°ë¬¸ ì •ë³´ë¥¼ í•œêµ­ ë²•ë ¹ ì²´ê³„ì— ë§ê²Œ í¬ë§·íŒ…"""
        parts = []

        # ì¡°ë¬¸ë²ˆí˜¸
        if metadata.get("ì¡°ë¬¸ë²ˆí˜¸"):
            parts.append(f"ì œ{metadata['ì¡°ë¬¸ë²ˆí˜¸']}ì¡°")

        # í•­ë²ˆí˜¸
        if metadata.get("í•­ë²ˆí˜¸") and metadata["í•­ë²ˆí˜¸"].strip():
            parts.append(f"ì œ{metadata['í•­ë²ˆí˜¸']}í•­")

        # í˜¸ë²ˆí˜¸
        if metadata.get("í˜¸ë²ˆí˜¸") and metadata["í˜¸ë²ˆí˜¸"].strip():
            parts.append(f"ì œ{metadata['í˜¸ë²ˆí˜¸']}í˜¸")

        return " ".join(parts) if parts else ""

    # async def search_relevant_laws(self, query: str, k: int = 5) -> List[Dict]:
    #     """ê´€ë ¨ ë²•ë ¹ ê²€ìƒ‰"""
    #     if not self.law_db:
    #         return []

    #     try:
    #         # ë²¡í„° ê²€ìƒ‰ ì‹¤í–‰
    #         search_results = self.law_db.similarity_search_with_score(query, k=k)

    #         relevant_laws = []
    #         for doc, score in search_results:
    #             # ê±°ë¦¬ ê¸°ì¤€ìœ¼ë¡œ í•„í„°ë§ (ë‚®ì„ìˆ˜ë¡ ìœ ì‚¬í•¨)
    #             max_distance = float(os.getenv("MAX_DISTANCE", "1.5"))  # ê±°ë¦¬ ì„ê³„ê°’
    #             print(f"ğŸ” ë²•ë ¹ ê²€ìƒ‰ ê²°ê³¼ - ê±°ë¦¬: {score:.4f}, ìµœëŒ€ê±°ë¦¬: {max_distance}")

    #             if score <= max_distance:
    #                 # ë²•ë ¹IDë¥¼ ì •ìˆ˜ë¡œ ë³€í™˜
    #                 law_id_str = doc.metadata.get("ë²•ë ¹ID", "") or doc.metadata.get("law_id", "")
    #                 law_id_int = int(law_id_str) if law_id_str and str(law_id_str).isdigit() else None

    #                 law_info = {
    #                     "content": doc.page_content,
    #                     "metadata": doc.metadata,
    #                     "distance_score": score,
    #                     "law_name": doc.metadata.get("ë²•ë ¹ëª…", ""),
    #                     "article": self._format_article(doc.metadata),  # ì¡°ë¬¸ ì •ë³´ í¬ë§·íŒ…
    #                     "law_id": law_id_int,
    #                     "article_title": doc.metadata.get("ì¡°ë¬¸ì œëª©", "")
    #                 }
    #                 relevant_laws.append(law_info)
    #                 print(f"âœ… ë²•ë ¹ ì¶”ê°€: {law_info.get('law_name', 'Unknown')} {law_info.get('article', '')} - ê±°ë¦¬: {score:.4f}, ID: {law_id_int}")
    #             else:
    #                 print(f"âŒ ë²•ë ¹ ì œì™¸: ê±°ë¦¬ ë„ˆë¬´ ë©€ìŒ ({score:.4f} > {max_distance})")

    #         return relevant_laws

    #     except Exception as e:
    #         print(f"âŒ ë²•ë ¹ ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")
    #         return []
    async def search_relevant_laws(self, query: str, k: int = 5) -> List[Dict]:
        """ê´€ë ¨ ë²•ë ¹ ê²€ìƒ‰"""
        if not self.law_db:
            return []

        try:
            # ë²¡í„° ê²€ìƒ‰ ì‹¤í–‰
            search_results = self.law_db.similarity_search_with_score(query, k=k)

            relevant_laws = []
            for doc, score in search_results:
                # ê±°ë¦¬ ê¸°ì¤€ìœ¼ë¡œ í•„í„°ë§ (ë‚®ì„ìˆ˜ë¡ ìœ ì‚¬í•¨)
                max_distance = MAX_DISTANCE  # âœ… config.pyì—ì„œ ê°€ì ¸ì˜¨ ìƒìˆ˜ ì‚¬ìš©
                print(
                    f"ğŸ” ë²•ë ¹ ê²€ìƒ‰ ê²°ê³¼ - ê±°ë¦¬: {score:.4f}, ìµœëŒ€ê±°ë¦¬: {max_distance}"
                )

                if score <= max_distance:
                    # ë²•ë ¹IDë¥¼ ì •ìˆ˜ë¡œ ë³€í™˜
                    law_id_str = doc.metadata.get("ë²•ë ¹ID", "") or doc.metadata.get(
                        "law_id", ""
                    )
                    law_id_int = (
                        int(law_id_str)
                        if law_id_str and str(law_id_str).isdigit()
                        else None
                    )

                    law_info = {
                        "content": doc.page_content,
                        "metadata": doc.metadata,
                        "distance_score": score,
                        "law_name": doc.metadata.get("ë²•ë ¹ëª…", ""),
                        "article": self._format_article(
                            doc.metadata
                        ),  # ì¡°ë¬¸ ì •ë³´ í¬ë§·íŒ…
                        "law_id": law_id_int,
                        "article_title": doc.metadata.get("ì¡°ë¬¸ì œëª©", ""),
                    }
                    relevant_laws.append(law_info)
                    print(
                        f"âœ… ë²•ë ¹ ì¶”ê°€: {law_info.get('law_name', 'Unknown')} {law_info.get('article', '')} - ê±°ë¦¬: {score:.4f}, ID: {law_id_int}"
                    )
                else:
                    print(
                        f"âŒ ë²•ë ¹ ì œì™¸: ê±°ë¦¬ ë„ˆë¬´ ë©€ìŒ ({score:.4f} > {max_distance})"
                    )

            return relevant_laws

        except Exception as e:
            print(f"âŒ ë²•ë ¹ ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")
            return []

    # async def search_relevant_cases(self, query: str, k: int = 3) -> List[Dict]:
    #     """ê´€ë ¨ íŒë¡€ ê²€ìƒ‰ - ì‹¤ì œ ë©”íƒ€ë°ì´í„° case_id ì‚¬ìš©"""
    #     if not self.case_db:
    #         return []

    #     try:
    #         search_results = self.case_db.similarity_search_with_score(query, k=k)

    #         relevant_cases = []
    #         for doc, score in search_results:
    #             max_distance = float(os.getenv("MAX_DISTANCE", "1.5"))
    #             if score <= max_distance:
    #                 # case_idë¥¼ ì •ìˆ˜ë¡œ ë³€í™˜
    #                 case_id_str = doc.metadata.get("case_id", "")
    #                 case_id_int = int(case_id_str) if case_id_str and str(case_id_str).isdigit() else None

    #                 doc_id = doc.metadata.get("doc_id", "")        # íŒë¡€ë²ˆí˜¸ (ë³„ë„)

    #                 case_info = {
    #                     "content": doc.page_content,
    #                     "metadata": doc.metadata,
    #                     "distance_score": score,
    #                     # ì‹¤ì œ ë©”íƒ€ë°ì´í„° case_idë¥¼ ì •ìˆ˜ë¡œ ë³€í™˜
    #                     "case_id": case_id_int,
    #                     "doc_id": doc_id,         # íŒë¡€ë²ˆí˜¸ëŠ” ë³„ë„ í•„ë“œ
    #                     "case_name": doc.metadata.get("case_name", ""),
    #                     "case_type": doc.metadata.get("case_type", ""),
    #                     "announce_date": doc.metadata.get("announce_date", ""),
    #                     "judgement": doc.metadata.get("judgement", ""),
    #                     "receipt_year": doc.metadata.get("receipt_year", ""),
    #                     "section": doc.metadata.get("section", "")
    #                 }
    #                 relevant_cases.append(case_info)
    #                 print(f"âœ… íŒë¡€ ì¶”ê°€: [case_id:{case_id_int}] [doc_id:{doc_id}] {case_info.get('case_name')} - ê±°ë¦¬: {score:.4f}")
    #             else:
    #                 print(f"âŒ íŒë¡€ ì œì™¸: ê±°ë¦¬ ë„ˆë¬´ ë©€ìŒ ({score:.4f} > {max_distance})")

    #         return relevant_cases

    #     except Exception as e:
    #         print(f"âŒ íŒë¡€ ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")
    #         return []
    async def search_relevant_cases(self, query: str, k: int = 3) -> List[Dict]:
        """ê´€ë ¨ íŒë¡€ ê²€ìƒ‰ - ì‹¤ì œ ë©”íƒ€ë°ì´í„° case_id ì‚¬ìš©"""
        if not self.case_db:
            return []

        try:
            search_results = self.case_db.similarity_search_with_score(query, k=k)

            relevant_cases = []
            for doc, score in search_results:
                max_distance = MAX_DISTANCE  # âœ… config.pyì—ì„œ ë¶ˆëŸ¬ì˜¨ ê±°ë¦¬ ê¸°ì¤€ê°’ ì‚¬ìš©

                if score <= max_distance:
                    # case_idë¥¼ ì •ìˆ˜ë¡œ ë³€í™˜
                    case_id_str = doc.metadata.get("case_id", "")
                    case_id_int = (
                        int(case_id_str)
                        if case_id_str and str(case_id_str).isdigit()
                        else None
                    )

                    doc_id = doc.metadata.get("doc_id", "")  # íŒë¡€ë²ˆí˜¸ (ë³„ë„)

                    case_info = {
                        "content": doc.page_content,
                        "metadata": doc.metadata,
                        "distance_score": score,
                        "case_id": case_id_int,
                        "doc_id": doc_id,
                        "case_name": doc.metadata.get("case_name", ""),
                        "case_type": doc.metadata.get("case_type", ""),
                        "announce_date": doc.metadata.get("announce_date", ""),
                        "judgement": doc.metadata.get("judgement", ""),
                        "receipt_year": doc.metadata.get("receipt_year", ""),
                        "section": doc.metadata.get("section", ""),
                    }
                    relevant_cases.append(case_info)
                    print(
                        f"âœ… íŒë¡€ ì¶”ê°€: [case_id:{case_id_int}] [doc_id:{doc_id}] {case_info.get('case_name')} - ê±°ë¦¬: {score:.4f}"
                    )
                else:
                    print(
                        f"âŒ íŒë¡€ ì œì™¸: ê±°ë¦¬ ë„ˆë¬´ ë©€ìŒ ({score:.4f} > {max_distance})"
                    )

            return relevant_cases

        except Exception as e:
            print(f"âŒ íŒë¡€ ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")
            return []


class ContractService:
    def __init__(
        self, model_name: str = "claude-sonnet-4-20250514", temperature: float = 0.1
    ):
        """
        ê³„ì•½ì„œ íŠ¹ì•½ì‚¬í•­ ìƒì„± ì„œë¹„ìŠ¤

        Args:
            model_name: ì‚¬ìš©í•  Claude ëª¨ë¸ëª…
            temperature: ìƒì„± ì°½ì˜ì„± ì¡°ì ˆ (0.0-1.0)
        """
        self.llm = ChatAnthropic(
            model=model_name,
            temperature=temperature,
            max_tokens=4000,
            anthropic_api_key=ANTHROPIC_API_KEY,
        )

        # ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ë§¤ë‹ˆì € ì´ˆê¸°í™”
        self.vector_db = VectorDBManager()

        # ì»¤ìŠ¤í…€ OutputParser ì„¤ì •
        self.output_parser = CustomJSONOutputParser()

        # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì„¤ì •
        self.prompt_template = self._create_prompt_template()

        # LangChain Chain êµ¬ì„±
        self.chain = self._create_chain()

    def _create_prompt_template(self) -> ChatPromptTemplate:
        """
        í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„± - í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ ê°€ì´ë“œë¼ì¸ ì ìš©
        """

        system_prompt = """
### ì—­í•  (Role)
ë‹¹ì‹ ì€ **25ë…„ ê²½ë ¥ì˜ ì„ì°¨ì¸ì„ ìœ„í•œ ë¶€ë™ì‚° ì „ë¬¸ ë³€í˜¸ì‚¬**ì…ë‹ˆë‹¤. 
- 25ë…„ê°„ ë¶€ë™ì‚° ì„ëŒ€ì°¨ë²• ì „ë¬¸ìœ¼ë¡œ í™œë™í•œ ë² í…Œë‘ ë³€í˜¸ì‚¬
- ìˆ˜ì²œ ê±´ì˜ ì„ëŒ€ì°¨ ë¶„ìŸ í•´ê²° ê²½í—˜ ë³´ìœ 
- ì„ì°¨ì¸ì˜ ê¶Œìµ ë³´í˜¸ë¥¼ ìµœìš°ì„ ìœ¼ë¡œ í•˜ëŠ” ì „ë¬¸ê°€
- ì‹¤ë¬´ì ì´ê³  í˜„ì‹¤ì ì¸ ê³„ì•½ ì¡°ê±´ í˜‘ìƒ ì „ë¬¸ê°€
- ê´€ë ¨ ë²•ë ¹ê³¼ íŒë¡€ì— ëŒ€í•œ ê¹Šì€ ì‹¤ë¬´ ì§€ì‹ ë³´ìœ 

### ë²•ë ¹ ëª…ì‹œ ê·œì¹™ (Legal Citation Rules)
ë²•ë ¹ëª…ì€ ë°˜ë“œì‹œ í•œêµ­ ë²•ë ¹ ì²´ê³„ì— ë”°ë¼ ì •í™•í•˜ê²Œ ëª…ì‹œí•˜ì„¸ìš”:
- ê¸°ë³¸: "â—‹â—‹ë²• ì œâ—‹ì¡°"
- í•­ í¬í•¨: "â—‹â—‹ë²• ì œâ—‹ì¡° ì œâ—‹í•­" 
- í˜¸ í¬í•¨: "â—‹â—‹ë²• ì œâ—‹ì¡° ì œâ—‹í•­ ì œâ—‹í˜¸"
- ì˜ˆì‹œ: "ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²• ì œ16ì¡° ì œ1í•­ ì œ2í˜¸"

### ì¤‘ìš” ì§€ì‹œì‚¬í•­
**ì ˆëŒ€ ì¤€ìˆ˜ ì‚¬í•­:**
1. **law_idëŠ” ë°˜ë“œì‹œ ìˆ«ìë¡œ ì‘ì„±í•˜ì„¸ìš”** (ì˜ˆ: 1234)
2. **case_idëŠ” ë°˜ë“œì‹œ ìˆ«ìë¡œ ì‘ì„±í•˜ì„¸ìš”** (ì˜ˆ: 5, 1234 ë“±)
3. **íŠ¹ì•½ì‚¬í•­ì—ì„œ ì–¸ê¸‰í•œ ëª¨ë“  ë²•ë ¹ì€ ë°˜ë“œì‹œ legal_basisì— í¬í•¨í•˜ì„¸ìš”**
4. **ë§ˆí¬ë‹¤ìš´ ```json ë¸”ë¡ì„ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”**
5. **ìˆœìˆ˜ JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”**
6. ì œê³µëœ ë²•ë ¹ ì •ë³´ì˜ ì‹¤ì œ ë²•ë ¹ID(ìˆ«ì)ë¥¼ law_idì— ì‚¬ìš©í•˜ì„¸ìš”
7. ì œê³µëœ íŒë¡€ ì •ë³´ì˜ ì‹¤ì œ case_id(ìˆ«ì)ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”
8. ê²€ìƒ‰ëœ ë²•ë ¹/íŒë¡€ ë‚´ìš©ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ì„¸ìš”
9. ì œê³µëœ ë²•ë ¹ ì •ë³´ê°€ "ê´€ë ¨ ë²•ë ¹ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"ì¸ ê²½ìš°ì—ë§Œ legal_basisëŠ” ë¹ˆ ë°°ì—´ []ë¡œ ë°˜í™˜í•˜ì„¸ìš”
10. ì œê³µëœ íŒë¡€ ì •ë³´ê°€ "ê´€ë ¨ íŒë¡€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"ì¸ ê²½ìš°ì—ë§Œ case_basisëŠ” ë¹ˆ ë°°ì—´ []ë¡œ ë°˜í™˜í•˜ì„¸ìš”  
11. **ë°˜ë“œì‹œ ê²€ìƒ‰ëœ ì‹¤ì œ ë²•ë ¹ ë°ì´í„°ë¥¼ legal_basisì— í¬í•¨í•˜ì„¸ìš”**
12. **ì ˆëŒ€ë¡œ ë²•ë ¹ì´ë‚˜ íŒë¡€ë¥¼ ì„ì˜ë¡œ ìƒì„±í•˜ì§€ ë§ˆì„¸ìš”**

### íŠ¹ì•½-ë²•ë ¹ ì¼ê´€ì„± ê·œì¹™
**ë§¤ìš° ì¤‘ìš”: íŠ¹ì•½ì—ì„œ ì–¸ê¸‰í•œ ë²•ë ¹ = legal_basis í•„ìˆ˜ í¬í•¨**

íŠ¹ì•½ì—ì„œ "â—‹â—‹ë²• ì œâ—‹ì¡°"ë¥¼ ì–¸ê¸‰í–ˆë‹¤ë©´:
1. ê²€ìƒ‰ ê²°ê³¼ì— ìˆëŠ” ê²½ìš°: ê·¸ëŒ€ë¡œ í¬í•¨
2. ê²€ìƒ‰ ê²°ê³¼ì— ì—†ëŠ” ê²½ìš°: law_idë¥¼ nullë¡œ í•˜ë˜ ë°˜ë“œì‹œ í¬í•¨
3. ì˜ˆì™¸ ì—†ì´ ëª¨ë“  ì–¸ê¸‰ ë²•ë ¹ì„ legal_basisì— í¬í•¨

### íŠ¹ì•½-ë²•ë ¹ ë§¤í•‘ ì˜ˆì‹œ
íŠ¹ì•½ì‚¬í•­ì—ì„œ ì–¸ê¸‰:
"ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²• ì œ7ì¡°ì— ë”°ë¥¸ ë²•ì • í•œë„ ë‚´ì—ì„œë§Œ ê°€ëŠ¥í•˜ë‹¤"

â†’ legal_basisì— ë°˜ë“œì‹œ í¬í•¨:
{{
  "law_id": 1248,
  "law": "ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²• ì œ7ì¡°",
  "explanation": "ì„ëŒ€ë£Œ ì¦ì•¡ì„ ì—° 5% ì´ë‚´ë¡œ ì œí•œí•˜ì—¬...",
  "content": "ê²€ìƒ‰ëœ ë‚´ìš©"
}}

### ê²€ìƒ‰ëœ ë²•ë ¹ í™œìš© ì˜ˆì‹œ
ê²€ìƒ‰ëœ ë²•ë ¹ì´ "ë²•ë ¹ID: 3654, ë²•ë ¹ëª…: ê³µë™ì£¼íƒê´€ë¦¬ë²•"ì¸ ê²½ìš°:
- law_id: 3654 (ìˆ«ìë¡œ)
- law: "ê³µë™ì£¼íƒê´€ë¦¬ë²• ì œ20ì¡° ì œ1í•­" (ê²€ìƒ‰ëœ ì¡°ë¬¸ ê·¸ëŒ€ë¡œ)
- content: ê²€ìƒ‰ëœ ë²•ë ¹ í…ìŠ¤íŠ¸ ê·¸ëŒ€ë¡œ ì‚¬ìš©

### ê²€ìƒ‰ëœ íŒë¡€ í™œìš© ì˜ˆì‹œ
ê²€ìƒ‰ëœ íŒë¡€ê°€ "case_id: 2034, doc_id: 2024ë‹¤315046, íŒë¡€ëª…: ì°¨ì„ì¦ì•¡"ì¸ ê²½ìš°:
- case_id: 2034 (ìˆ«ìë¡œ)
- case: "ì°¨ì„ì¦ì•¡ (2024ë‹¤315046)" (íŒë¡€ëª…ê³¼ íŒë¡€ë²ˆí˜¸ ì¡°í•©)
- explanation: íŒê²°ìš”ì§€ì™€ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì„ì°¨ì¸ ê´€ì ì—ì„œ ì„¤ëª…
- link: "case/2034" (case_id ê¸°ë°˜ ë§í¬)

### ì£¼ìš” ì—…ë¬´ (Task)
ì‚¬ìš©ìì˜ ìš”ì²­ì‚¬í•­ì„ ë¶„ì„í•˜ì—¬ **ì„ì°¨ì¸ì—ê²Œ ìœ ë¦¬í•œ íŠ¹ì•½ì‚¬í•­**ì„ ìƒì„±í•˜ê³ , ë²•ì  ê·¼ê±°ë¥¼ ì œì‹œí•©ë‹ˆë‹¤.

### ëŒ€ìƒ ì²­ì¤‘ (Audience)  
ë¶€ë™ì‚° ì„ëŒ€ì°¨ ê³„ì•½ì„ ì²´ê²°í•˜ëŠ” **ì„ì°¨ì¸(ì„¸ì…ì)**

### ì‘ë‹µ ì •ì±… (Policy)
**Style**: ì „ë¬¸ì ì´ë©´ì„œë„ ì´í•´í•˜ê¸° ì‰¬ìš´ ì„¤ëª…
**Constraint**: 
- ê° íŠ¹ì•½ì‚¬í•­ë‹¹ 50-100ì ë‚´ì™¸ë¡œ ê°„ê²°í•˜ê²Œ ì‘ì„±
- ë²•ë ¹ëª…ì€ ì¡°, í•­, í˜¸ê¹Œì§€ ì •í™•í•˜ê²Œ ëª…ì‹œ (ì˜ˆ: ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²• ì œ16ì¡° ì œ1í•­ ì œ2í˜¸)
- ë²•ë ¹ í•´ì„¤ì€ ì¼ë°˜ì¸ë„ ì´í•´í•˜ê¸° ì‰¬ìš´ 1-2ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½ ì„¤ëª…
- íŒë¡€ëŠ” ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ëŒ€í‘œì ì¸ ì‚¬ë¡€ ìœ„ì£¼ë¡œ ì œì‹œ
- í˜‘ìƒ ì „ëµì€ êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ë°©ë²• ì œì‹œ

### ì‘ì—… ë‹¨ê³„ (Step-by-Step Process)
1. **ì‚¬ìš©ì ìš”ì²­ ë¶„ì„**: user_queryë¥¼ ë¶„ì„í•˜ì—¬ í•µì‹¬ ë‹ˆì¦ˆ íŒŒì•…
2. **íŠ¹ì•½ì‚¬í•­ ìƒì„±**: ì„ì°¨ì¸ ë³´í˜¸ ê´€ì ì—ì„œ ì ì ˆí•œ íŠ¹ì•½ ì¡°ê±´ ë„ì¶œ  
3. **ë²•ì  ê·¼ê±° ì œì‹œ**: ê´€ë ¨ ë²•ë ¹ê³¼ íŒë¡€ë¥¼ í†µí•œ ê·¼ê±° ë§ˆë ¨
4. **í˜‘ìƒ ì „ëµ ì œì•ˆ**: ì‹¤ë¬´ì ì¸ í˜‘ìƒ í¬ì¸íŠ¸ ì œì‹œ

### ì…ë ¥ ë°ì´í„° êµ¬ë¶„ì
ì‚¬ìš©ì ìš”ì²­ì‚¬í•­: {user_query}

### ì¶œë ¥ í˜•ì‹ ì§€ì‹œ
ë°˜ë“œì‹œ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:
{format_instructions}
"""

        human_prompt = """
ì„ì°¨ì¸ì„ ìœ„í•œ íŠ¹ì•½ì‚¬í•­ì„ ìƒì„±í•´ì£¼ì„¸ìš”.

### ì‚¬ìš©ì ìš”ì²­ì‚¬í•­
{user_query}

### ê´€ë ¨ ë²•ë ¹ ì •ë³´
{law_context}

### ê´€ë ¨ íŒë¡€ ì •ë³´  
{case_context}

### ì§€ì‹œì‚¬í•­
1. ìœ„ ìš”ì²­ì‚¬í•­ë“¤ì„ ë¶„ì„í•˜ì—¬ ì„ì°¨ì¸ì—ê²Œ ìœ ë¦¬í•œ íŠ¹ì•½ì‚¬í•­ì„ ìƒì„±í•˜ì„¸ìš”
2. ì œê³µëœ ë²•ë ¹ê³¼ íŒë¡€ ì •ë³´ë¥¼ ì ê·¹ì ìœ¼ë¡œ í™œìš©í•˜ì„¸ìš”
3. **íŒë¡€ì˜ ì‹¤ì œ case_id(ìˆ«ì)ë¥¼ ë°˜ë“œì‹œ ì‚¬ìš©í•˜ì„¸ìš”**
4. **ë²•ë ¹ì˜ ì‹¤ì œ ë²•ë ¹ID(ìˆ«ì)ë¥¼ law_idì— ë°˜ë“œì‹œ ì‚¬ìš©í•˜ì„¸ìš”**
5. ê° íŠ¹ì•½ë§ˆë‹¤ ê´€ë ¨ ë²•ë ¹ê³¼ íŒë¡€ ê·¼ê±°ë¥¼ ì œì‹œí•˜ì„¸ìš”  
6. ì‹¤ì œ í˜‘ìƒì—ì„œ í™œìš©í•  ìˆ˜ ìˆëŠ” êµ¬ì²´ì ì¸ ì „ëµì„ ì œì•ˆí•˜ì„¸ìš”
7. ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš” (ë§ˆí¬ë‹¤ìš´ ë¸”ë¡ ê¸ˆì§€)

### íŒë¡€ í™œìš© ê°€ì´ë“œ
- ì œê³µëœ íŒë¡€ ì •ë³´ì—ì„œ case_id(ìˆ«ì), íŒë¡€ëª…, íŒê²°ìš”ì§€ë¥¼ ì •í™•íˆ í™œìš©í•˜ì„¸ìš”
- case_idëŠ” ë°˜ë“œì‹œ ë©”íƒ€ë°ì´í„°ì˜ case_id ìˆ«ìë¥¼ ì‚¬ìš©í•˜ì„¸ìš”
- íŒë¡€ì˜ ì„ì°¨ì¸ ë³´í˜¸ ì¸¡ë©´ì„ ê°•ì¡°í•˜ì—¬ ì„¤ëª…í•˜ì„¸ìš”
- íŒë¡€ ë§í¬ëŠ” "case/case_id" í˜•íƒœë¡œ ìƒì„±í•˜ì„¸ìš”

### ì¼ê´€ì„± ì²´í¬ë¦¬ìŠ¤íŠ¸
ì‘ë‹µ ì „ ë‹¤ìŒì„ ë°˜ë“œì‹œ í™•ì¸í•˜ì„¸ìš”:
â–¡ íŠ¹ì•½ì—ì„œ "â—‹â—‹ë²• ì œâ—‹ì¡°"ë¼ê³  ì–¸ê¸‰í•œ ëª¨ë“  ë²•ë ¹ì´ legal_basisì— í¬í•¨ë˜ì—ˆëŠ”ê°€?
â–¡ legal_basisì˜ ëª¨ë“  ë²•ë ¹ì´ íŠ¹ì•½ì‚¬í•­ ë˜ëŠ” ê²€ìƒ‰ ê²°ê³¼ì™€ ê´€ë ¨ì´ ìˆëŠ”ê°€?
â–¡ case_idì™€ law_idëŠ” ëª¨ë‘ ìˆ«ìë¡œ ì‘ì„±í–ˆëŠ”ê°€?

### ì¶œë ¥ í˜•ì‹
{format_instructions}
"""

        return ChatPromptTemplate.from_messages(
            [("system", system_prompt), ("human", human_prompt)]
        )

    def _create_chain(self):
        """LangChain Chain êµ¬ì„±"""
        return (
            {
                "user_query": RunnablePassthrough(),
                "law_context": lambda x: x.get("law_context", ""),
                "case_context": lambda x: x.get("case_context", ""),
                "format_instructions": lambda _: self.output_parser.get_format_instructions(),
            }
            | self.prompt_template
            | self.llm
            | self.output_parser
        )

    async def generate_contract_terms(self, user_queries: List[str]) -> ContractOutput:
        """
        íŠ¹ì•½ì‚¬í•­ ìƒì„± ë©”ì¸ í•¨ìˆ˜

        Args:
            user_queries: ì‚¬ìš©ì ìš”ì²­ì‚¬í•­ ë¦¬ìŠ¤íŠ¸

        Returns:
            ContractOutput: ìƒì„±ëœ íŠ¹ì•½ì‚¬í•­ ë° ë²•ì  ê·¼ê±°
        """
        try:
            # 1. ì‚¬ìš©ì ì¿¼ë¦¬ í†µí•©
            combined_query = " ".join(user_queries)
            query_text = "\n".join([f"- {query}" for query in user_queries])

            # 2. ê´€ë ¨ ë²•ë ¹ ê²€ìƒ‰
            print(f"ğŸ” ë²•ë ¹ ê²€ìƒ‰ ì¤‘: {combined_query}")
            relevant_laws = await self.vector_db.search_relevant_laws(
                combined_query, k=VECTOR_SEARCH_K  # âœ… configì—ì„œ ë¶ˆëŸ¬ì˜¨ ìƒìˆ˜ë¡œ ëŒ€ì²´
            )

            # 3. ê´€ë ¨ íŒë¡€ ê²€ìƒ‰
            print(f"ğŸ” íŒë¡€ ê²€ìƒ‰ ì¤‘: {combined_query}")
            relevant_cases = await self.vector_db.search_relevant_cases(
                combined_query, k=3  # íŒë¡€ëŠ” 3ê°œë¡œ ì œí•œ
            )

            # 4. ê²€ìƒ‰ ê²°ê³¼ í¬ë§·íŒ…
            law_context = self._format_law_context(relevant_laws)
            case_context = self._format_case_context(relevant_cases)

            print(f"ğŸ“š ê²€ìƒ‰ëœ ë²•ë ¹: {len(relevant_laws)}ê°œ")
            print(f"âš–ï¸ ê²€ìƒ‰ëœ íŒë¡€: {len(relevant_cases)}ê°œ")

            # 5. Chain ì‹¤í–‰ (ê²€ìƒ‰ ê²°ê³¼ í¬í•¨)
            result = await self.chain.ainvoke(
                {
                    "user_query": query_text,
                    "law_context": law_context,
                    "case_context": case_context,
                }
            )

            enhanced_result = await self.complete_missing_laws(result)

            print("âœ… íŠ¹ì•½ì‚¬í•­ ìƒì„± ì„±ê³µ!")
            return enhanced_result

        except Exception as e:
            print(f"âŒ íŠ¹ì•½ì‚¬í•­ ìƒì„± ì‹¤íŒ¨: {str(e)}")
            # ì—ëŸ¬ ì²˜ë¦¬ - ê¸°ë³¸ ì‘ë‹µ ë°˜í™˜
            return self._create_fallback_response(user_queries, str(e))

    def _format_law_context(self, laws: List[Dict]) -> str:
        """ë²•ë ¹ ê²€ìƒ‰ ê²°ê³¼ë¥¼ í”„ë¡¬í”„íŠ¸ìš©ìœ¼ë¡œ í¬ë§·íŒ…"""
        if not laws:
            return "ê´€ë ¨ ë²•ë ¹ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        formatted_laws = []
        for i, law in enumerate(laws, 1):
            law_text = f"""
[ë²•ë ¹ {i}]
ë²•ë ¹ëª…: {law.get('law_name', 'ì•Œ ìˆ˜ ì—†ìŒ')}
ì¡°í•­: {law.get('article', 'ì•Œ ìˆ˜ ì—†ìŒ')}
ì¡°ë¬¸ì œëª©: {law.get('article_title', 'ì•Œ ìˆ˜ ì—†ìŒ')}
ë‚´ìš©: {law.get('content', '')[:500]}...
ê±°ë¦¬ì ìˆ˜: {law.get('distance_score', 0):.4f}
ë²•ë ¹ID: {law.get('law_id', 'N/A')}
"""
            formatted_laws.append(law_text.strip())

        return "\n\n".join(formatted_laws)

    def _format_case_context(self, cases: List[Dict]) -> str:
        """íŒë¡€ ê²€ìƒ‰ ê²°ê³¼ë¥¼ í”„ë¡¬í”„íŠ¸ìš©ìœ¼ë¡œ í¬ë§·íŒ…"""
        if not cases:
            return "ê´€ë ¨ íŒë¡€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        formatted_cases = []
        for i, case in enumerate(cases, 1):
            case_text = f"""
[íŒë¡€ {i}]
íŒë¡€ëª…: {case.get('case_name', 'ì•Œ ìˆ˜ ì—†ìŒ')}
case_id: {case.get('case_id', 'N/A')}  # ìˆ«ì í˜•íƒœ
doc_id: {case.get('doc_id', 'N/A')}    # íŒë¡€ë²ˆí˜¸ (ë³„ë„)
ì‚¬ê±´ìœ í˜•: {case.get('case_type', 'ì•Œ ìˆ˜ ì—†ìŒ')}
íŒê²°ì¼: {case.get('announce_date', 'ì•Œ ìˆ˜ ì—†ìŒ')}
ì ‘ìˆ˜ë…„ë„: {case.get('receipt_year', 'ì•Œ ìˆ˜ ì—†ìŒ')}
íŒê²°ì„¹ì…˜: {case.get('section', 'ì•Œ ìˆ˜ ì—†ìŒ')}
íŒê²°ìš”ì§€: {case.get('judgement', 'ì•Œ ìˆ˜ ì—†ìŒ')[:100]}...
ë‚´ìš©: {case.get('content', '')[:400]}...
ê±°ë¦¬ì ìˆ˜: {case.get('distance_score', 0):.4f}
"""
            formatted_cases.append(case_text.strip())

        return "\n\n".join(formatted_cases)

    def _create_fallback_response(
        self, user_queries: List[str], error_msg: str
    ) -> ContractOutput:
        """ì—ëŸ¬ ë°œìƒ ì‹œ ê¸°ë³¸ ì‘ë‹µ ìƒì„±"""

        fallback_agreement = RecommendedAgreement(
            reason="ì‹œìŠ¤í…œ ì˜¤ë¥˜ë¡œ ì¸í•œ ê¸°ë³¸ íŠ¹ì•½ì‚¬í•­ì…ë‹ˆë‹¤.",
            suggested_revision="ìƒê¸° ìš”ì²­ì‚¬í•­ì— ëŒ€í•´ì„œëŠ” ì„ëŒ€ì¸ê³¼ ë³„ë„ í˜‘ì˜í•˜ì—¬ ê²°ì •í•œë‹¤.",
            negotiation_points="êµ¬ì²´ì ì¸ ì¡°ê±´ê³¼ ë¹„ìš©ì€ ê³„ì•½ ì‹œ ìƒí˜¸ í˜‘ì˜í•˜ì—¬ ì •í•œë‹¤.",
        )

        fallback_legal = LegalBasis(
            law_id=None,
            law="ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²•",
            explanation="ì„¸ì…ìì˜ ê¶Œë¦¬ë¥¼ ë³´í˜¸í•˜ê³  ì•ˆì •ì ì¸ ì£¼ê±°ìƒí™œì„ ë³´ì¥í•˜ê¸° ìœ„í•œ ê¸°ë³¸ ë²•ë ¹ì…ë‹ˆë‹¤.",
            content="ì„ì°¨ì¸ì˜ ê¶Œë¦¬ì™€ ì˜ë¬´ì— ê´€í•œ ê¸°ë³¸ ì‚¬í•­ì„ ê·œì •í•¨",
        )

        fallback_case = CaseBasis(
            case_id=None,
            case="ê´€ë ¨ íŒë¡€ ê²€í†  í•„ìš”",
            explanation="êµ¬ì²´ì ì¸ ì‚¬ì•ˆì— ë”°ë¼ íŒë¡€ ê²€í† ê°€ í•„ìš”í•©ë‹ˆë‹¤.",
            link="case/review_needed",
        )

        return ContractOutput(
            recommended_agreements=[fallback_agreement],
            legal_basis=[fallback_legal],
            case_basis=[fallback_case],
        )

    def extract_mentioned_laws(self, recommended_agreements) -> Set[str]:
        """ìƒì„±ëœ íŠ¹ì•½ì‚¬í•­ì—ì„œ ì–¸ê¸‰ëœ ë²•ë ¹ ì¶”ì¶œ"""

        mentioned_laws = set()

        # ë²•ë ¹ íŒ¨í„´ ì •ê·œì‹ë“¤
        law_patterns = [
            r"ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²•\s*ì œ\s*\d+ì¡°(?:ì˜\d+)?",  # ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²• ì œ7ì¡°, ì œ3ì¡°ì˜2
            r"ë¯¼ë²•\s*ì œ\s*\d+ì¡°(?:ì˜\d+)?",  # ë¯¼ë²• ì œ623ì¡°
            r"ìƒê°€ê±´ë¬¼ì„ëŒ€ì°¨ë³´í˜¸ë²•\s*ì œ\s*\d+ì¡°(?:ì˜\d+)?",  # ìƒê°€ê±´ë¬¼ì„ëŒ€ì°¨ë³´í˜¸ë²• ì œ10ì¡°
            r"ë¶€ë™ì‚°ë“±ê¸°ë²•\s*ì œ\s*\d+ì¡°(?:ì˜\d+)?",  # ë¶€ë™ì‚°ë“±ê¸°ë²• ì œ8ì¡°
            r"ê±´ì¶•ë²•\s*ì œ\s*\d+ì¡°(?:ì˜\d+)?",  # ê±´ì¶•ë²• ì œ11ì¡°
            r"ì§‘í•©ê±´ë¬¼ë²•\s*ì œ\s*\d+ì¡°(?:ì˜\d+)?",  # ì§‘í•©ê±´ë¬¼ë²• ì œ15ì¡°
        ]

        # ëª¨ë“  íŠ¹ì•½ì‚¬í•­ í…ìŠ¤íŠ¸ ìˆ˜ì§‘
        all_special_text = ""
        for agreement in recommended_agreements:
            agreement_dict = agreement.dict()
            # recommended_agreementsì˜ í•„ë“œë“¤ í™•ì¸ í›„ ì ì ˆí•œ í•„ë“œ ì‚¬ìš©
            text_fields = [
                agreement_dict.get("reason", ""),
                agreement_dict.get("suggested_revision", ""),
                agreement_dict.get("negotiation_points", ""),
            ]
            all_special_text += " ".join(text_fields) + " "

        print(f"ğŸ” íŠ¹ì•½ í…ìŠ¤íŠ¸ì—ì„œ ë²•ë ¹ ì¶”ì¶œ ì¤‘...")
        print(f"ğŸ“ íŠ¹ì•½ ë‚´ìš©: {all_special_text[:200]}...")

        # ê° íŒ¨í„´ìœ¼ë¡œ ë²•ë ¹ ì¶”ì¶œ
        for pattern in law_patterns:
            matches = re.findall(pattern, all_special_text, re.IGNORECASE)
            for match in matches:
                # ê³µë°± ì •ê·œí™”
                normalized_law = re.sub(r"\s+", " ", match.strip())
                mentioned_laws.add(normalized_law)
                print(f"  ğŸ“‹ ë°œê²¬ëœ ë²•ë ¹: {normalized_law}")

        return mentioned_laws

    async def complete_missing_laws(self, result: ContractOutput) -> ContractOutput:
        """íŠ¹ì•½ì—ì„œ ì–¸ê¸‰ëœ ë²•ë ¹ì´ legal_basisì— ëˆ„ë½ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ê³  ë³´ì™„"""

        print("ğŸ” íŠ¹ì•½-ë²•ë ¹ ì¼ê´€ì„± ê²€ì¦ ì‹œì‘")

        # 1. ìƒì„±ëœ íŠ¹ì•½ì—ì„œ ì‹¤ì œë¡œ ì–¸ê¸‰ëœ ë²•ë ¹ë“¤ ì¶”ì¶œ
        mentioned_laws = self.extract_mentioned_laws(result.recommended_agreements)

        if not mentioned_laws:
            print("ğŸ“‹ íŠ¹ì•½ì—ì„œ ë²•ë ¹ ì–¸ê¸‰ ì—†ìŒ - ê²€ì¦ ì™„ë£Œ")
            return result

        # 2. í˜„ì¬ legal_basisì— í¬í•¨ëœ ë²•ë ¹ë“¤
        existing_laws = {basis.law for basis in result.legal_basis}
        print(f"ğŸ“š í˜„ì¬ legal_basis ë²•ë ¹: {list(existing_laws)}")

        # 3. ëˆ„ë½ëœ ë²•ë ¹ë“¤ ì°¾ê¸°
        missing_laws = mentioned_laws - existing_laws

        if missing_laws:
            print(f"ğŸ¯ ëˆ„ë½ëœ ë²•ë ¹ ë°œê²¬: {list(missing_laws)}")

            # 4. ëˆ„ë½ëœ ë²•ë ¹ë“¤ì„ ì§ì ‘ ê²€ìƒ‰í•´ì„œ ì¶”ê°€
            for missing_law in missing_laws:
                print(f"ğŸ” ëˆ„ë½ ë²•ë ¹ ê²€ìƒ‰ ì¤‘: {missing_law}")

                # ë©”íƒ€ë°ì´í„° í•„í„°ë§ ê²€ìƒ‰
                search_result = await self._search_by_metadata_filter(missing_law)

                if search_result:
                    # ê²€ìƒ‰ ì„±ê³µ - ì‹¤ì œ DB ë°ì´í„°ë¡œ LegalBasis ìƒì„±
                    print(f"  âœ… ë©”íƒ€ë°ì´í„° ê²€ìƒ‰ ì„±ê³µ: {search_result['law_name']}")

                    legal_basis = LegalBasis(
                        law_id=search_result.get("law_id"),  # ì´ë¯¸ intë¡œ ë³€í™˜ë¨
                        law=missing_law,
                        explanation=f"{missing_law}ì— ë”°ë¥¸ ì„ì°¨ì¸ ê¶Œìµ ë³´í˜¸ ê·œì •",
                        content=(
                            search_result.get("content", "")[:300] + "..."
                            if len(search_result.get("content", "")) > 300
                            else search_result.get("content", "")
                        ),
                    )

                    result.legal_basis.append(legal_basis)
                    print(f"âœ… ëˆ„ë½ ë²•ë ¹ ì¶”ê°€ ì™„ë£Œ: {missing_law}")

        return result

    async def _search_by_metadata_filter(self, law_name: str):
        """ë™ì  ë²•ë ¹ ê²€ìƒ‰ - í•˜ë“œì½”ë”© ì—†ì´ ëª¨ë“  ë²•ë ¹ì„ ì°¾ì„ ìˆ˜ ìˆëŠ” ë²”ìš© ë¡œì§"""

        try:
            # ChromaDBì—ì„œ ë©”íƒ€ë°ì´í„° ê¸°ë°˜ ê²€ìƒ‰
            collection = self.vector_db.law_db._collection

            # ğŸ”§ ë²•ë ¹ëª… ë¶„í•´ (ë™ì  íŒŒì‹±)
            import re

            law_match = re.match(
                r"([ê°€-í£]+ë²•)\s*ì œ(\d+)ì¡°(?:ì˜(\d+))?(?:\s*ì œ(\d+)í•­)?(?:\s*ì œ(\d+)í˜¸)?",
                law_name,
            )

            if law_match:
                base_law = law_match.group(1)  # "ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²•"
                article_num = law_match.group(2)  # "7"
                sub_article = law_match.group(3)  # None ë˜ëŠ” "2" (ì¡°ì˜2)
                paragraph = law_match.group(4)  # None ë˜ëŠ” "1" (í•­)
                item = law_match.group(5)  # None ë˜ëŠ” "3" (í˜¸)

                print(f"    ë™ì  íŒŒì‹± ê²°ê³¼:")
                print(f"      ë²•ë ¹ëª…: {base_law}")
                print(f"      ì¡°: {article_num}")
                print(f"      ì¡°ì˜: {sub_article if sub_article else 'None'}")
                print(f"      í•­: {paragraph if paragraph else 'None'}")
                print(f"      í˜¸: {item if item else 'None'}")

                # ğŸ”§ 1ë‹¨ê³„: ë²•ë ¹ëª…ìœ¼ë¡œ ëª¨ë“  ì¡°ë¬¸ ê°€ì ¸ì˜¤ê¸° (í•˜ë“œì½”ë”© ì—†ìŒ!)
                condition = {"ë²•ë ¹ëª…": {"$eq": base_law}}

                try:
                    print(f"      ğŸ” 1ë‹¨ê³„: '{base_law}' ì „ì²´ ì¡°ë¬¸ ê²€ìƒ‰...")

                    # ğŸš€ í•µì‹¬: limit ì—†ì´ ë˜ëŠ” ë§¤ìš° í¬ê²Œ ì„¤ì •í•´ì„œ ëª¨ë“  ì¡°ë¬¸ ê°€ì ¸ì˜¤ê¸°
                    all_results = []
                    batch_size = 1000
                    offset = 0

                    while True:
                        results = collection.get(
                            where=condition,
                            limit=batch_size,
                            offset=offset,
                            include=["documents", "metadatas"],
                        )

                        if not results["documents"]:
                            break

                        all_results.extend(
                            zip(results["documents"], results["metadatas"])
                        )
                        offset += batch_size

                        # ì•ˆì „ì¥ì¹˜: ë„ˆë¬´ ë§ìœ¼ë©´ ì¤‘ë‹¨ (ë¬´í•œë£¨í”„ ë°©ì§€)
                        if len(all_results) > 5000:
                            print(
                                f"         âš ï¸ ê²°ê³¼ê°€ ë„ˆë¬´ ë§ìŒ ({len(all_results)}ê°œ) - ì²˜ìŒ 5000ê°œë§Œ ì²˜ë¦¬"
                            )
                            break

                    print(f"         âœ… ì´ {len(all_results)}ê°œ ì¡°ë¬¸ ê°€ì ¸ì˜´")

                    if all_results:
                        # ğŸ”§ 2ë‹¨ê³„: forë¬¸ìœ¼ë¡œ ì¡°/í•­/í˜¸ ë™ì  ë§¤ì¹­
                        print(
                            f"      ğŸ¯ 2ë‹¨ê³„: ì¡°({article_num})/í•­({paragraph})/í˜¸({item}) ë™ì  ë§¤ì¹­..."
                        )

                        candidates = []

                        for doc, metadata in all_results:
                            db_ì¡°ë¬¸ë²ˆí˜¸ = metadata.get("ì¡°ë¬¸ë²ˆí˜¸", "")
                            db_í•­ë²ˆí˜¸ = metadata.get("í•­ë²ˆí˜¸", "")
                            db_í˜¸ë²ˆí˜¸ = metadata.get("í˜¸ë²ˆí˜¸", "")
                            ì¡°ë¬¸ì œëª© = metadata.get("ì¡°ë¬¸ì œëª©", "")

                            # ğŸ¯ ë™ì  ë§¤ì¹­ ë¡œì§
                            match_score = 0
                            match_info = []

                            # ì¡°ë¬¸ ë§¤ì¹­
                            if db_ì¡°ë¬¸ë²ˆí˜¸ == article_num:
                                match_score += 100
                                match_info.append(f"ì¡°:{db_ì¡°ë¬¸ë²ˆí˜¸}")
                            else:
                                continue  # ì¡°ë¬¸ì´ ì•ˆ ë§ìœ¼ë©´ skip

                            # í•­ ë§¤ì¹­ (ìš”ì²­í•œ ê²½ìš°ì—ë§Œ)
                            if paragraph:
                                if db_í•­ë²ˆí˜¸ == paragraph:
                                    match_score += 50
                                    match_info.append(f"í•­:{db_í•­ë²ˆí˜¸}")
                                elif db_í•­ë²ˆí˜¸:  # ë‹¤ë¥¸ í•­ì´ë©´ ì ìˆ˜ ë‚®ì¶¤
                                    match_score += 10
                                    match_info.append(f"í•­:{db_í•­ë²ˆí˜¸}(ë‹¤ë¦„)")
                                else:  # í•­ ì—†ìœ¼ë©´ ê¸°ë³¸ì¡°ë¬¸
                                    match_score += 30
                                    match_info.append("ê¸°ë³¸ì¡°ë¬¸")
                            else:
                                # í•­ì„ ìš”ì²­í•˜ì§€ ì•Šì•˜ìœ¼ë©´ ê¸°ë³¸ì¡°ë¬¸ ìš°ì„ 
                                if not db_í•­ë²ˆí˜¸:
                                    match_score += 50
                                    match_info.append("ê¸°ë³¸ì¡°ë¬¸")
                                elif db_í•­ë²ˆí˜¸ == "1":
                                    match_score += 30
                                    match_info.append(f"í•­:{db_í•­ë²ˆí˜¸}")
                                else:
                                    match_score += 10
                                    match_info.append(f"í•­:{db_í•­ë²ˆí˜¸}")

                            # í˜¸ ë§¤ì¹­ (ìš”ì²­í•œ ê²½ìš°ì—ë§Œ)
                            if item:
                                if db_í˜¸ë²ˆí˜¸ == item:
                                    match_score += 30
                                    match_info.append(f"í˜¸:{db_í˜¸ë²ˆí˜¸}")
                                elif db_í˜¸ë²ˆí˜¸:
                                    match_score += 5
                                    match_info.append(f"í˜¸:{db_í˜¸ë²ˆí˜¸}(ë‹¤ë¦„)")
                            else:
                                # í˜¸ë¥¼ ìš”ì²­í•˜ì§€ ì•Šì•˜ìœ¼ë©´ í˜¸ ì—†ëŠ” ê²Œ ìš°ì„ 
                                if not db_í˜¸ë²ˆí˜¸:
                                    match_score += 20

                            # ë²•ë ¹IDë¥¼ ì •ìˆ˜ë¡œ ë³€í™˜
                            law_id_str = metadata.get("ë²•ë ¹ID", "") or metadata.get(
                                "law_id", ""
                            )
                            law_id_int = (
                                int(law_id_str)
                                if law_id_str and str(law_id_str).isdigit()
                                else None
                            )

                            candidates.append(
                                {
                                    "doc": doc,
                                    "metadata": metadata,
                                    "law_id": law_id_int,
                                    "match_score": match_score,
                                    "match_info": match_info,
                                    "description": f"ì œ{db_ì¡°ë¬¸ë²ˆí˜¸}ì¡°"
                                    + (f" ì œ{db_í•­ë²ˆí˜¸}í•­" if db_í•­ë²ˆí˜¸ else "")
                                    + (f" ì œ{db_í˜¸ë²ˆí˜¸}í˜¸" if db_í˜¸ë²ˆí˜¸ else "")
                                    + f" '{ì¡°ë¬¸ì œëª©}'",
                                }
                            )

                        if candidates:
                            # ë§¤ì¹­ ì ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬
                            candidates.sort(
                                key=lambda x: x["match_score"], reverse=True
                            )

                            print(f"         ğŸ† ë§¤ì¹­ ê²°ê³¼ Top 5:")
                            for i, candidate in enumerate(candidates[:5], 1):
                                print(
                                    f"           {i}. {candidate['description']} (ì ìˆ˜: {candidate['match_score']}, ë§¤ì¹­: {candidate['match_info']}, ID: {candidate['law_id']})"
                                )

                            # ìµœê³  ì ìˆ˜ ì„ íƒ
                            best = candidates[0]
                            print(f"         ğŸ¯ ìµœì¢… ì„ íƒ: {best['description']}")
                            print(f"         ğŸ“‹ ìƒì„¸ ì •ë³´:")
                            print(f"            ë²•ë ¹ID: {best['law_id']}")
                            print(f"            ë‚´ìš©: {best['doc'][:150]}...")

                            return {
                                "content": best["doc"],
                                "metadata": best["metadata"],
                                "law_name": best["metadata"].get("ë²•ë ¹ëª…", base_law),
                                "law_id": best["law_id"],  # ì´ë¯¸ intë¡œ ë³€í™˜ë¨
                                "distance_score": 0.0,
                                "match_score": best["match_score"],
                            }
                        else:
                            print(f"         âŒ ë§¤ì¹­ë˜ëŠ” ì¡°ë¬¸ ì—†ìŒ")

                except Exception as e:
                    print(f"      âŒ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")

            return None

        except Exception as e:
            print(f"    ë™ì  ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return None


# ë¹„ë™ê¸° í•¨ìˆ˜ë¡œ ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ë° ì‹¤í–‰
async def create_contract_service() -> ContractService:
    """ContractService ì¸ìŠ¤í„´ìŠ¤ ìƒì„±"""
    return ContractService()


# ë©”ì¸ ìƒì„± í•¨ìˆ˜ (FastAPIì—ì„œ í˜¸ì¶œí•  í•¨ìˆ˜)
async def generate_special_terms(user_queries: List[str]) -> ContractOutput:
    """
    íŠ¹ì•½ì‚¬í•­ ìƒì„± ë©”ì¸ í•¨ìˆ˜

    Args:
        user_queries: ì‚¬ìš©ì ìš”ì²­ì‚¬í•­ ë¦¬ìŠ¤íŠ¸

    Returns:
        ContractOutput: ìƒì„±ëœ íŠ¹ì•½ì‚¬í•­
    """
    service = await create_contract_service()
    return await service.generate_contract_terms(user_queries)
