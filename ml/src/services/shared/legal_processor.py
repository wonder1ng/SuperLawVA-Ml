"""
[services/shared/legal_processor.py] - ë²•ë ¹ ì²˜ë¦¬ ê³µí†µ ì„œë¹„ìŠ¤ (ìˆ˜ì •ëœ ë²„ì „)

legal_basis ìƒì„± ë¬¸ì œ í•´ê²°
"""

import re
from typing import List, Set, Optional, Dict
from services.schema.shared_schema import LegalReference, LegalBasis

def normalize_law_name(law_name: str) -> str:
        """
        ë²•ë ¹ëª…ì„ ì •ê·œí™”í•˜ì—¬ ë§¤ì¹­ ì„±ê³µë¥  í–¥ìƒ
        """
        if not law_name:
            return ""
        
        # 1. ê³µë°± ì œê±°
        normalized = law_name.replace(" ", "").strip()
        
        # 2. ë‹¤ì–‘í•œ ì¤‘ì  ë¬¸ìë“¤ì„ í†µì¼ (ê°€ì¥ ì¤‘ìš”!)
        normalized = normalized.replace("ã†", "Â·")  # ê°€ìš´ëƒì  â†’ ì¤‘ì 
        normalized = normalized.replace("âˆ™", "Â·")   # bullet â†’ ì¤‘ì   
        normalized = normalized.replace("â€¢", "Â·")   # bullet â†’ ì¤‘ì 
        normalized = normalized.replace("â€¤", "Â·")   # one dot leader â†’ ì¤‘ì 
        
        # 3. ê¸°íƒ€ íŠ¹ìˆ˜ë¬¸ì ì •ê·œí™”
        normalized = normalized.replace("ï½", "~")   # ì „ê° ë¬¼ê²°í‘œ â†’ ë°˜ê°
        normalized = normalized.replace("ï¼ˆ", "(")   # ì „ê° ê´„í˜¸ â†’ ë°˜ê°
        normalized = normalized.replace("ï¼‰", ")")   # ì „ê° ê´„í˜¸ â†’ ë°˜ê°
        
        # 4. í•˜ì´í”ˆ ì •ê·œí™”
        normalized = normalized.replace("ï¼", "-")   # ì „ê° í•˜ì´í”ˆ â†’ ë°˜ê°
        normalized = normalized.replace("â€”", "-")    # em dash â†’ í•˜ì´í”ˆ
        normalized = normalized.replace("â€“", "-")    # en dash â†’ í•˜ì´í”ˆ
        
        return normalized

class LegalProcessor:
    """ë²•ë ¹ ì²˜ë¦¬ ê³µí†µ ì„œë¹„ìŠ¤ (ìˆ˜ì •ëœ ë²„ì „)"""
    
    def __init__(self, llm):
        self.llm = llm
        # ê¸°ì¡´ íŒ¨í„´ ìœ ì§€
        self.law_pattern = re.compile(
            r"(?:ã€Œ)?(?P<law>[ê°€-í£Â·\w\d\s]{2,}?(ë²•|ì‹œí–‰ë ¹|ì‹œí–‰ê·œì¹™))(?:ã€)?\s*ì œ\s*(?P<article>\d+)\s*ì¡°(?:\s*ì œ\s*(?P<clause>\d+)\s*í•­)?(?:\s*ì œ\s*(?P<item>\d+)\s*í˜¸)?",
            re.UNICODE
        )
        
        # ê°œì„ ëœ íŒ¨í„´ ì¶”ê°€ - ã€Œã€ë¡œ ê°ì‹¸ì§„ ëª¨ë“  ë²•ë ¹ëª… ë§¤ì¹­
        self.improved_law_pattern = re.compile(
            r"ã€Œ(?P<law>[^ã€]+)ã€\s*ì œ\s*(?P<article>\d+)\s*ì¡°(?:\s*ì œ\s*(?P<clause>\d+)\s*í•­)?(?:\s*ì œ\s*(?P<item>\d+)\s*í˜¸)?",
            re.UNICODE
        )
    
    def extract_referenced_laws(self, text: str) -> Set[str]:
            """
            í…ìŠ¤íŠ¸ì—ì„œ ì°¸ì¡°ëœ ë²•ë ¹ì„ ì¶”ì¶œí•˜ë˜, ë‹¤ë¥¸ ë²•ë ¹ ë‚´ìš©ì— ì¸ìš©ëœ ë²•ë ¹ì€ ì œì™¸ (ìˆ˜ì •ëœ ë²„ì „)
            """
            
            print(f"[DEBUG] ë²•ë ¹ ì¶”ì¶œ ì‹œì‘...")
            print(f"[DEBUG] ì…ë ¥ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(text)}")
            
            # 1ë‹¨ê³„: ì¸ìš©ëœ ë²•ë ¹ë“¤ ì°¾ê¸° (ë‹¤ì–‘í•œ ì¸ìš© íŒ¨í„´ ëŒ€ì‘)
            quoted_laws = self.find_quoted_laws(text)
            
            # 2ë‹¨ê³„: ëª¨ë“  ë²•ë ¹ ì¶”ì¶œ (ê¸°ì¡´ ë¡œì§ ì‚¬ìš©)
            all_laws = self.extract_all_laws_original(text)
            
            # 3ë‹¨ê³„: ì¸ìš©ëœ ë²•ë ¹ë“¤ ì œì™¸ (ë¶€ë¶„ ë§¤ì¹­ìœ¼ë¡œ ìˆ˜ì •)
            filtered_laws = set()
            
            for law in all_laws:
                should_exclude = False
                
                for quoted_law in quoted_laws:
                    # ë¶€ë¶„ ë¬¸ìì—´ ë§¤ì¹­ (ë²•ë ¹ëª… ê¸°ì¤€)
                    if quoted_law in law:
                        should_exclude = True
                        print(f"[DEBUG] âœ‚ï¸ ì œì™¸ë¨: '{law}' (ì¸ìš©ëœ ë²•ë ¹: '{quoted_law}' í¬í•¨)")
                        break
                
                if not should_exclude:
                    filtered_laws.add(law)
                    print(f"[DEBUG] âœ… í¬í•¨ë¨: '{law}'")
            
            print(f"[DEBUG] ì „ì²´ ì¶”ì¶œëœ ë²•ë ¹: {len(all_laws)}ê°œ")
            print(f"[DEBUG] ì¸ìš©ìœ¼ë¡œ ì œì™¸ëœ ë²•ë ¹: {len(quoted_laws)}ê°œ - {quoted_laws}")
            print(f"[DEBUG] ìµœì¢… í•„í„°ë§ëœ ë²•ë ¹: {len(filtered_laws)}ê°œ - {filtered_laws}")
            
            return filtered_laws


    def find_quoted_laws(self, text: str) -> Set[str]:
        """
        ì‘ì€ë”°ì˜´í‘œ ì•ˆì— ìˆëŠ” ëª¨ë“  ë²•ë ¹ëª… ì°¾ê¸° (ê°œì„ ëœ ë²„ì „)
        """
        quoted_laws = set()
        
        # ì‘ì€ë”°ì˜´í‘œ ì•ˆì˜ ë‚´ìš©ì„ ëª¨ë‘ ì¶”ì¶œ
        quote_pattern = r"'([^']*?)'"
        matches = re.finditer(quote_pattern, text, re.DOTALL)
        
        for match in matches:
            quoted_text = match.group(1).strip()
            print(f"[DEBUG] ë”°ì˜´í‘œ ì•ˆ ë°œê²¬: '{quoted_text}'")
            
            # ë”°ì˜´í‘œ ì•ˆì—ì„œ ë²•ë ¹ëª… ì°¾ê¸° (ê°œì„ ëœ íŒ¨í„´)
            law_patterns = [
                # íŒ¨í„´ 1: ã€Œë²•ë ¹ëª…ã€ í˜•íƒœ
                r'ã€Œ([^ã€]+)ã€',
                # íŒ¨í„´ 2: ë²•ë ¹ëª… (ì¡°í•­ ì œì™¸í•˜ê³  ìˆœìˆ˜ ë²•ë ¹ëª…ë§Œ)
                r'([ê°€-í£Â·\w\d\s]{2,}?(?:ë²•|ì‹œí–‰ë ¹|ì‹œí–‰ê·œì¹™))(?=\s|$|ì œ|\s*ì—|\s*ì˜)'
            ]
            
            for i, pattern in enumerate(law_patterns):
                law_matches = re.finditer(pattern, quoted_text)
                for law_match in law_matches:
                    law_name = law_match.group(1).strip()
                    
                    # í•„í„°ë§: ì˜ë¯¸ì—†ëŠ” ë‹¨ì–´ë“¤ ì œì™¸
                    invalid_words = ['ì´', 'ì—', 'ì˜', 'ì„', 'ë¥¼', 'ê³¼', 'ì™€', 'ì„ì°¨ì¸ì´', 'ì— ë”°ë¼ ì „ì…ì‹ ê³ ë¥¼ í•˜ëŠ” ê²½ìš° ì´']
                    
                    if (len(law_name) > 3 and 
                        law_name not in invalid_words and 
                        not any(word in law_name for word in invalid_words)):
                        
                        quoted_laws.add(law_name)
                        print(f"[DEBUG] íŒ¨í„´ {i+1}ë¡œ ì¸ìš© ë²•ë ¹ ë°œê²¬: {law_name}")
        
        return quoted_laws

    def extract_all_laws_original(self, text: str) -> Set[str]:
            """
            ê¸°ì¡´ ë²•ë ¹ ì¶”ì¶œ ë¡œì§ (ëª¨ë“  ë²•ë ¹ ì¶”ì¶œ)
            """
            referenced_laws = set()
            
            # 1. ê°œì„ ëœ íŒ¨í„´ìœ¼ë¡œ ë¨¼ì € ë§¤ì¹­ (ã€Œã€ë¡œ ê°ì‹¸ì§„ ë²•ë ¹)
            improved_matches = list(self.improved_law_pattern.finditer(text))
            print(f"[DEBUG] ê°œì„ ëœ íŒ¨í„´ ë§¤ì¹­ ê²°ê³¼: {len(improved_matches)}ê°œ")
            
            for match in improved_matches:
                law = match.group("law").strip()
                article = match.group("article")
                clause = match.group("clause")
                item = match.group("item")
                
                key = f"{law} ì œ{article}ì¡°"
                if clause:
                    key += f" ì œ{clause}í•­"
                if item:
                    key += f" ì œ{item}í˜¸"
                    
                referenced_laws.add(key)
                print(f"[DEBUG] ê°œì„ ëœ íŒ¨í„´ìœ¼ë¡œ ì¶”ì¶œ: {key}")
            
            # 2. ê¸°ì¡´ íŒ¨í„´ìœ¼ë¡œ ì¶”ê°€ ë§¤ì¹­ (ëˆ„ë½ëœ ê²ƒë“¤ ì°¾ê¸°)
            original_matches = list(self.law_pattern.finditer(text))
            print(f"[DEBUG] ê¸°ì¡´ íŒ¨í„´ ë§¤ì¹­ ê²°ê³¼: {len(original_matches)}ê°œ")
            
            for match in original_matches:
                law = match.group("law").strip()
                article = match.group("article")
                clause = match.group("clause")
                item = match.group("item")
                
                key = f"{law} ì œ{article}ì¡°"
                if clause:
                    key += f" ì œ{clause}í•­"
                if item:
                    key += f" ì œ{item}í˜¸"
                    
                referenced_laws.add(key)
                print(f"[DEBUG] ê¸°ì¡´ íŒ¨í„´ìœ¼ë¡œ ì¶”ì¶œ: {key}")
            
            print(f"[DEBUG] ìµœì¢… ì¶”ì¶œëœ ë²•ë ¹ë“¤: {referenced_laws}")
            print(f"[DEBUG] ì´ {len(referenced_laws)}ê°œ ë²•ë ¹ ì¶”ì¶œë¨")
            
            return referenced_laws
    
    async def generate_law_summary(self, full_text: str) -> str:
            """ë²•ë ¹ ìš”ì•½ ìƒì„± (ëª¨ë“  ê¸°ëŠ¥ì—ì„œ ì‚¬ìš©)"""
            summary_prompt = f"""
            ë‹¤ìŒ ë²•ë ¹ ì¡°ë¬¸ì´ ì‚¬ìš©ìì—ê²Œ ì œê³µí•˜ëŠ” ê¶Œë¦¬ë‚˜ ë²•ì  ë³´í˜¸ë¥¼ 1-2ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”:
            "{full_text}"
            """
            try:
                response = await self.llm.ainvoke(summary_prompt)
                return response.content.strip()
            except Exception as e:
                print(f"[DEBUG] ë²•ë ¹ ìš”ì•½ ìƒì„± ì˜¤ë¥˜: {e}")
                return "ë²•ë ¹ ìš”ì•½ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
        
    def find_law_document(self, reference: str, law_docs: list):
        """ì°¸ì¡°ëœ ë²•ë ¹ì— í•´ë‹¹í•˜ëŠ” ë¬¸ì„œ ì°¾ê¸° (ì™„ì „ ìˆ˜ì • ë²„ì „)"""
        print(f"[DEBUG] *** ì™„ì „ ìˆ˜ì •ëœ find_law_document í•¨ìˆ˜ ì‹¤í–‰ ***")
        print(f"[DEBUG] ê²€ìƒ‰ ëŒ€ìƒ: {reference}")
        print(f"[DEBUG] ê²€ìƒ‰í•  ë¬¸ì„œ ê°œìˆ˜: {len(law_docs)}")
        
        # === ë‹¤ì–‘í•œ ì •ê·œì‹ íŒ¨í„´ë“¤ ===
        patterns = [
            # íŒ¨í„´ 1: ã€Œë²•ë ¹ëª…ã€ ì œXì¡° ì œYí•­ ì œZí˜¸
            re.compile(r"ã€Œ([^ã€]+)ã€\s*ì œ\s*(\d+)\s*ì¡°(?:\s*ì œ\s*(\d+)\s*í•­)?(?:\s*ì œ\s*(\d+)\s*í˜¸)?", re.UNICODE),
            
            # íŒ¨í„´ 2: ë²•ë ¹ëª… ì œXì¡° ì œYí•­ ì œZí˜¸ (ã€Œã€ ì—†ìŒ)
            re.compile(r"(.+?)\s+ì œ\s*(\d+)\s*ì¡°(?:\s*ì œ\s*(\d+)\s*í•­)?(?:\s*ì œ\s*(\d+)\s*í˜¸)?", re.UNICODE),
            
            # íŒ¨í„´ 3: ê¸°ì¡´ íŒ¨í„´ (ë°±ì—…ìš©)
            re.compile(r"(?:ã€Œ)?([^ã€]*?(ë²•|ì‹œí–‰ë ¹|ì‹œí–‰ê·œì¹™))(?:ã€)?\s*ì œ\s*(\d+)\s*ì¡°(?:\s*ì œ\s*(\d+)\s*í•­)?(?:\s*ì œ\s*(\d+)\s*í˜¸)?", re.UNICODE)
        ]
        
        # === ì •ê·œì‹ ë§¤ì¹­ ì‹œë„ ===
        law_name = None
        article = None
        clause = None
        item = None
        
        for i, pattern in enumerate(patterns):
            match = pattern.search(reference)
            if match:
                print(f"[DEBUG] íŒ¨í„´ {i} ë§¤ì¹­ ì„±ê³µ!")
                groups = match.groups()
                print(f"[DEBUG] ë§¤ì¹­ ê·¸ë£¹ë“¤: {groups}")
                
                if i == 0:  # íŒ¨í„´ 1
                    law_name, article, clause, item = groups
                elif i == 1:  # íŒ¨í„´ 2
                    law_name, article, clause, item = groups
                elif i == 2:  # íŒ¨í„´ 3
                    law_name = groups[0]  # ì²« ë²ˆì§¸ ê·¸ë£¹ì´ ë²•ë ¹ëª…
                    article = groups[2]   # ì„¸ ë²ˆì§¸ ê·¸ë£¹ì´ ì¡°ë¬¸ë²ˆí˜¸
                    clause = groups[3] if len(groups) > 3 else None
                    item = groups[4] if len(groups) > 4 else None
                
                law_name = law_name.strip() if law_name else ""
                print(f"[DEBUG] íŒŒì‹± ê²°ê³¼ - ë²•ë ¹: '{law_name}', ì¡°: '{article}', í•­: '{clause}', í˜¸: '{item}'")
                break
            else:
                print(f"[DEBUG] íŒ¨í„´ {i} ë§¤ì¹­ ì‹¤íŒ¨")
        
        if not law_name or not article:
            print(f"[DEBUG] ì •ê·œì‹ ë§¤ì¹­ ì™„ì „ ì‹¤íŒ¨: {reference}")
            return None
        
        # === 1ë‹¨ê³„: ë²•ë ¹ëª…ìœ¼ë¡œ í•„í„°ë§ ===
        law_name_normalized = normalize_law_name(law_name)
        matching_law_docs = []
        
        print(f"[DEBUG] 1ë‹¨ê³„: ë²•ë ¹ëª… '{law_name_normalized}' í•„í„°ë§ (ì •ê·œí™” ì ìš©)")
        for i, doc in enumerate(law_docs):
            doc_law_name = doc.metadata.get("ë²•ë ¹ëª…", "")
            doc_law_name_normalized = normalize_law_name(doc_law_name)
            print(f"[DEBUG] ë¬¸ì„œ {i}: '{doc_law_name_normalized}' vs '{law_name_normalized}'")
            
            if doc_law_name_normalized == law_name_normalized:
                matching_law_docs.append(doc)
                print(f"[DEBUG] âœ… ë²•ë ¹ëª… ë§¤ì¹­ (ì •ê·œí™”): {doc.metadata}")
        
        if not matching_law_docs:
            print(f"[DEBUG] âŒ ë²•ë ¹ëª… ë§¤ì¹­ ì‹¤íŒ¨ (ì •ê·œí™” í›„): {law_name_normalized}")
            return None
        
        print(f"[DEBUG] 1ë‹¨ê³„ ê²°ê³¼: {len(matching_law_docs)}ê°œ ë¬¸ì„œ")
        
        # === 2ë‹¨ê³„: ì¡°ë¬¸ë²ˆí˜¸ë¡œ í•„í„°ë§ ===
        matching_article_docs = []
        
        print(f"[DEBUG] 2ë‹¨ê³„: ì¡°ë¬¸ë²ˆí˜¸ '{article}' í•„í„°ë§")
        for doc in matching_law_docs:
            doc_article = str(doc.metadata.get("ì¡°ë¬¸ë²ˆí˜¸", "")).strip()
            print(f"[DEBUG] ì¡°ë¬¸ ë¹„êµ: '{doc_article}' vs '{article}'")
            
            if doc_article == article:
                matching_article_docs.append(doc)
                print(f"[DEBUG] âœ… ì¡°ë¬¸ ë§¤ì¹­: {doc.metadata}")
        
        if not matching_article_docs:
            print(f"[DEBUG] âŒ ì¡°ë¬¸ ë§¤ì¹­ ì‹¤íŒ¨: ì œ{article}ì¡°")
            return None
        
        print(f"[DEBUG] 2ë‹¨ê³„ ê²°ê³¼: {len(matching_article_docs)}ê°œ ë¬¸ì„œ")
        
        # === 3ë‹¨ê³„: í•­ë²ˆí˜¸ë¡œ í•„í„°ë§ (ì„ íƒì ) ===
        final_docs = matching_article_docs
        
        if clause:
            print(f"[DEBUG] 3ë‹¨ê³„: í•­ë²ˆí˜¸ '{clause}' í•„í„°ë§")
            clause_docs = []
            for doc in matching_article_docs:
                doc_clause = str(doc.metadata.get("í•­ë²ˆí˜¸", "")).strip()
                print(f"[DEBUG] í•­ ë¹„êµ: '{doc_clause}' vs '{clause}'")
                
                if doc_clause == clause:
                    clause_docs.append(doc)
                    print(f"[DEBUG] âœ… í•­ ë§¤ì¹­: {doc.metadata}")
            
            if clause_docs:
                final_docs = clause_docs
                print(f"[DEBUG] 3ë‹¨ê³„ ê²°ê³¼: {len(final_docs)}ê°œ ë¬¸ì„œ")
            else:
                print(f"[DEBUG] âš ï¸ í•­ ë§¤ì¹­ ì‹¤íŒ¨, ì¡°ë¬¸ ë ˆë²¨ ìœ ì§€")
        
        # === 4ë‹¨ê³„: í˜¸ë²ˆí˜¸ë¡œ í•„í„°ë§ (ì„ íƒì ) ===
        if item:
            print(f"[DEBUG] 4ë‹¨ê³„: í˜¸ë²ˆí˜¸ '{item}' í•„í„°ë§")
            item_docs = []
            for doc in final_docs:
                doc_item = str(doc.metadata.get("í˜¸ë²ˆí˜¸", "")).strip()
                print(f"[DEBUG] í˜¸ ë¹„êµ: '{doc_item}' vs '{item}'")
                
                if doc_item == item:
                    item_docs.append(doc)
                    print(f"[DEBUG] âœ… í˜¸ ë§¤ì¹­: {doc.metadata}")
            
            if item_docs:
                final_docs = item_docs
                print(f"[DEBUG] 4ë‹¨ê³„ ê²°ê³¼: {len(final_docs)}ê°œ ë¬¸ì„œ")
            else:
                print(f"[DEBUG] âš ï¸ í˜¸ ë§¤ì¹­ ì‹¤íŒ¨, ìƒìœ„ ë ˆë²¨ ìœ ì§€")
        
        # === ìµœì¢… ë°˜í™˜ ===
        if final_docs:
            result_doc = final_docs[0]
            print(f"[DEBUG] ğŸ¯ ìµœì¢… ì„ íƒ ë¬¸ì„œ: {result_doc.metadata}")
            return result_doc
        else:
            print(f"[DEBUG] âŒ ìµœì¢… ë¬¸ì„œ ì—†ìŒ")
            return None
    
    async def generate_legal_explanations(self, referenced_laws: Set[str], law_docs: list) -> List[LegalReference]:
        """ë²•ë ¹ ìƒì„¸ ì„¤ëª… ìƒì„± (ê°œì„ ëœ ë²„ì „)"""
        print(f"[DEBUG] ë²•ë ¹ ì„¤ëª… ìƒì„± ì‹œì‘...")
        print(f"[DEBUG] ì²˜ë¦¬í•  ë²•ë ¹ ê°œìˆ˜: {len(referenced_laws)}")
        print(f"[DEBUG] ì‚¬ìš© ê°€ëŠ¥í•œ law_docs ê°œìˆ˜: {len(law_docs)}")
        
        legal_explanations = []
        
        for law_ref in referenced_laws:
            print(f"[DEBUG] ì²˜ë¦¬ ì¤‘ì¸ ë²•ë ¹: {law_ref}")
            
            target_doc = self.find_law_document(law_ref, law_docs)
            if not target_doc:
                print(f"[DEBUG] ë¬¸ì„œë¥¼ ì°¾ì§€ ëª»í•¨: {law_ref}")
                # ë¬¸ì„œë¥¼ ì°¾ì§€ ëª»í•´ë„ ê¸°ë³¸ ì •ë³´ëŠ” ì¶”ê°€
                legal_explanations.append(
                    LegalReference(
                        title=law_ref,
                        full_text=f"{law_ref}ì— ê´€í•œ ë‚´ìš©",
                        summary=f"{law_ref}ì— ê´€í•œ ë²•ì  ê·œì •",
                        law_id="0"
                    )
                )
                continue
            
            full_text = target_doc.page_content.strip().replace("\n", " ")
            summary = await self.generate_law_summary(full_text)
            
            # ì‹¤ì œ ë²•ë ¹ID ì¶”ì¶œ
            law_id = target_doc.metadata.get("ë²•ë ¹ID", "") or target_doc.metadata.get("law_id", "")
            if not law_id:
                law_id = "0"
            
            print(f"[DEBUG] ë²•ë ¹ ì„¤ëª… ìƒì„± ì™„ë£Œ: {law_ref}")
            
            legal_explanations.append(
                LegalReference(
                    title=law_ref,
                    full_text=full_text,
                    summary=summary,
                    law_id=str(law_id)
                )
            )
        
        print(f"[DEBUG] ì´ {len(legal_explanations)}ê°œ ë²•ë ¹ ì„¤ëª… ìƒì„±ë¨")
        return legal_explanations
    
    async def analyze_law_for_review(self, law_doc, clause_text: str) -> Dict[str, str]:
        """ê³„ì•½ì„œ ê²€í† ìš© ë²•ë ¹ ë¶„ì„"""
        law_text = law_doc.page_content.strip().replace("\n", " ")
        
        analysis_prompt = f"""
        ë‹¤ìŒ ê³„ì•½ ì¡°í•­ì´ ë²•ë ¹ì— ìœ„ë°°ë˜ëŠ”ì§€ ë¶„ì„í•´ì£¼ì„¸ìš”:
        
        ê³„ì•½ ì¡°í•­: {clause_text}
        ê´€ë ¨ ë²•ë ¹: {law_text}
        
        ë¶„ì„ ê²°ê³¼ë¥¼ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”:
        **ìœ„í—˜ë„**: medium/low
        **ë¬¸ì œì **: êµ¬ì²´ì ì¸ ë²•ì  ë¬¸ì œ
        **ê¶Œì¥ì‚¬í•­**: ìˆ˜ì • ì œì•ˆ
        """
        
        try:
            response = await self.llm.ainvoke(analysis_prompt)
            content = response.content.strip()
            
            # ë¶„ì„ ê²°ê³¼ íŒŒì‹±
            risk_level = "medium"  # ê¸°ë³¸ê°’
            issues = ""
            recommendations = ""
            
            lines = content.split('\n')
            for line in lines:
                if '**ìœ„í—˜ë„**' in line:
                    risk_level = line.split(':')[-1].strip()
                elif '**ë¬¸ì œì **' in line:
                    issues = line.split(':')[-1].strip()
                elif '**ê¶Œì¥ì‚¬í•­**' in line:
                    recommendations = line.split(':')[-1].strip()
            
            return {
                "risk_level": risk_level,
                "issues": issues,
                "recommendations": recommendations,
                "law_summary": await self.generate_law_summary(law_text)
            }
            
        except Exception as e:
            print(f"[DEBUG] ë²•ë ¹ ë¶„ì„ ì˜¤ë¥˜: {e}")
            return {
                "risk_level": "unknown",
                "issues": "ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ",
                "recommendations": "ì „ë¬¸ê°€ ìƒë‹´ ê¶Œì¥",
                "law_summary": "ë²•ë ¹ ìš”ì•½ ì‹¤íŒ¨"
            }
    
    def convert_to_legal_basis(self, legal_explanations: List[LegalReference]) -> List[LegalBasis]:
        """LegalReferenceë¥¼ LegalBasisë¡œ ë³€í™˜ - ì‹¤ì œ ë²•ë ¹ID ì‚¬ìš©"""
        print(f"[DEBUG] LegalBasis ë³€í™˜ ì‹œì‘: {len(legal_explanations)}ê°œ")
        
        legal_basis = []
        for ref in legal_explanations:
            # ì‹¤ì œ ë²•ë ¹IDê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ 0
            law_id = int(ref.law_id) if ref.law_id and ref.law_id.isdigit() else 0
            
            legal_basis.append(
                LegalBasis(
                    law_id=law_id,
                    law=ref.title,
                    explanation=ref.summary or "ë²•ë ¹ ì„¤ëª…",
                    content=ref.full_text or "ë²•ë ¹ ë‚´ìš©"
                )
            )
            print(f"[DEBUG] ë³€í™˜ë¨: {ref.title} -> law_id={law_id}")
        
        print(f"[DEBUG] LegalBasis ë³€í™˜ ì™„ë£Œ: {len(legal_basis)}ê°œ")
        return legal_basis

    # ê¸°ì¡´ í•¨ìˆ˜ëª…ë“¤ í˜¸í™˜ì„± ìœ ì§€
    def _find_law_document(self, reference: str, law_docs: list):
        """ê¸°ì¡´ í•¨ìˆ˜ëª… í˜¸í™˜ì„± ìœ ì§€"""
        return self.find_law_document(reference, law_docs)
    
    async def _generate_law_summary(self, full_text: str) -> str:
        """ê¸°ì¡´ í•¨ìˆ˜ëª… í˜¸í™˜ì„± ìœ ì§€"""
        return await self.generate_law_summary(full_text)

# ë°ì´í„° ë³€í™˜ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ (ê°œì„ ëœ ë²„ì „)
def convert_to_legal_basis(legal_explanations: List[LegalReference]) -> List[LegalBasis]:
    """ë‚´ìš©ì¦ëª…ìš© LegalBasis ë³€í™˜ (ë…ë¦½ í•¨ìˆ˜, ê°œì„ ëœ ë²„ì „)"""
    print(f"[DEBUG] convert_to_legal_basis í•¨ìˆ˜ í˜¸ì¶œ: {len(legal_explanations)}ê°œ")
    
    legal_basis = []
    for ref in legal_explanations:
        # ì‹¤ì œ ë²•ë ¹IDê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ 0
        law_id = int(ref.law_id) if ref.law_id and ref.law_id.isdigit() else 0
        
        legal_basis.append(
            LegalBasis(
                law_id=law_id,
                law=ref.title,
                explanation=ref.summary or "ë²•ë ¹ ì„¤ëª…",
                content=ref.full_text or "ë²•ë ¹ ë‚´ìš©"
            )
        )
        print(f"[DEBUG] ë…ë¦½í•¨ìˆ˜ ë³€í™˜ë¨: {ref.title} -> law_id={law_id}")
    
    print(f"[DEBUG] ë…ë¦½í•¨ìˆ˜ ë³€í™˜ ì™„ë£Œ: {len(legal_basis)}ê°œ")
    return legal_basis

def convert_to_review_format(legal_explanations: List[LegalReference], analysis_results: List[Dict]) -> List[Dict]:
    """ê³„ì•½ì„œ ê²€í† ìš© í˜•ì‹ ë³€í™˜"""
    review_results = []
    for ref, analysis in zip(legal_explanations, analysis_results):
        review_results.append({
            "law_title": ref.title,
            "law_summary": ref.summary,
            "risk_level": analysis.get("risk_level", "medium"),
            "issues": analysis.get("issues", ""),
            "recommendations": analysis.get("recommendations", ""),
            "law_id": ref.law_id
        })
    return review_results