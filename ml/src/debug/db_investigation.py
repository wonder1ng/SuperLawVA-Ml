# db_investigation.py - ë…ë¦½ ì‹¤í–‰ DB ì¡°ì‚¬ íŒŒì¼
"""
Description:  
ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²• ê´€ë ¨ Chroma ë²¡í„°DBì˜ ê²€ìƒ‰ ì„±ëŠ¥, ë©”íƒ€ë°ì´í„° êµ¬ì¡°, ì¡°ë¬¸ í¬í•¨ ì—¬ë¶€(íŠ¹íˆ ì œ7ì¡°) ë“±ì„ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„í•˜ëŠ” ë…ë¦½ ì‹¤í–‰í˜• ìŠ¤í¬ë¦½íŠ¸

Author: ooheunsu  
Date: 2025-06-16  
Requirements: langchain-chroma, langchain-openai, python-dotenv, asyncio
"""
import os
import asyncio
import re
from typing import List, Dict, Any
from langchain_chroma import Chroma
from langchain_openai import OpenAIEmbeddings
from dotenv import load_dotenv

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

class DatabaseInvestigator:
    """ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²• DB ì¡°ì‚¬ ì „ìš© í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.embeddings = OpenAIEmbeddings(model="text-embedding-3-large")
        self.law_db = None
        self._initialize_db()
    
    def _initialize_db(self):
        """ë²•ë ¹ DB ì—°ê²°"""
        try:
            law_db_path = os.getenv("CHROMA_LAW_DB_PATH", "./vectordb/chroma_law/chroma_openai_law")
            law_collection_name = os.getenv("LAW_COLLECTION_NAME", "law_chunks_openai")
            
            if os.path.exists(law_db_path):
                self.law_db = Chroma(
                    persist_directory=law_db_path,
                    embedding_function=self.embeddings,
                    collection_name=law_collection_name
                )
                print(f"âœ… ë²•ë ¹ DB ì—°ê²° ì„±ê³µ: {law_db_path}")
                print(f"ğŸ“‹ ì»¬ë ‰ì…˜ëª…: {law_collection_name}")
                
                # ì´ ë°ì´í„° ê°œìˆ˜ í™•ì¸
                try:
                    collection_count = self.law_db._collection.count()
                    print(f"ğŸ“Š ì´ ë²•ë ¹ ë°ì´í„°: {collection_count}ê°œ")
                except Exception as e:
                    print(f"âš ï¸ ë°ì´í„° ê°œìˆ˜ í™•ì¸ ì‹¤íŒ¨: {e}")
            else:
                print(f"âŒ ë²•ë ¹ DB ê²½ë¡œ ì—†ìŒ: {law_db_path}")
                
        except Exception as e:
            print(f"âŒ DB ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    
    async def search_laws(self, query: str, k: int = 5) -> List[Dict]:
        """ë²•ë ¹ ê²€ìƒ‰ (ê¸°ì¡´ VectorDBManager ë°©ì‹ê³¼ ë™ì¼)"""
        if not self.law_db:
            return []
        
        try:
            search_results = self.law_db.similarity_search_with_score(query, k=k)
            
            results = []
            for doc, score in search_results:
                max_distance = float(os.getenv("MAX_DISTANCE", "1.5"))
                
                if score <= max_distance:
                    law_info = {
                        "content": doc.page_content,
                        "metadata": doc.metadata,
                        "distance_score": score,
                        "law_name": doc.metadata.get("ë²•ë ¹ëª…", ""),
                        "law_id": doc.metadata.get("ë²•ë ¹ID", None),
                    }
                    results.append(law_info)
            
            return results
            
        except Exception as e:
            print(f"âŒ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return []
    
    async def comprehensive_investigation(self):
        """ì¢…í•©ì ì¸ DB ì¡°ì‚¬"""
        
        print("\n" + "="*80)
        print("ğŸ” ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²• DB ì¢…í•© ì¡°ì‚¬ ì‹œì‘")
        print("="*80)
        
        # 1ë‹¨ê³„: ê¸°ë³¸ í‚¤ì›Œë“œ ê²€ìƒ‰
        await self._investigate_basic_keywords()
        
        # 2ë‹¨ê³„: ë²•ë ¹ëª… ë³€í˜• ê²€ìƒ‰
        await self._investigate_law_variations()
        
        # 3ë‹¨ê³„: ë‚´ìš© ê¸°ë°˜ ê²€ìƒ‰
        await self._investigate_content_search()
        
        # 4ë‹¨ê³„: ë©”íƒ€ë°ì´í„° êµ¬ì¡° ë¶„ì„
        await self._investigate_metadata()
        
        # 5ë‹¨ê³„: í†µê³„ ë¶„ì„
        await self._investigate_statistics()
        
        print("\n" + "="*80)
        print("ğŸ¯ ì¡°ì‚¬ ê²°ê³¼ ìš”ì•½")
        print("="*80)
        await self._generate_summary()
        
        print("\n" + "="*80)
        print("ğŸ” DB ì¡°ì‚¬ ì™„ë£Œ")
        print("="*80)
    
    async def _investigate_basic_keywords(self):
        """1ë‹¨ê³„: ê¸°ë³¸ í‚¤ì›Œë“œ ê²€ìƒ‰"""
        
        print("\n" + "ğŸ“‹ 1ë‹¨ê³„: ê¸°ë³¸ í‚¤ì›Œë“œ ê²€ìƒ‰")
        print("-" * 50)
        
        keywords = [
            "ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²•",
            "ì£¼íƒì„ëŒ€ì°¨", 
            "ì„ëŒ€ì°¨ë³´í˜¸ë²•",
            "ì„ëŒ€ë£Œ ì¦ì•¡",
            "ì°¨ì„ ì¦ì•¡",
            "5í¼ì„¼íŠ¸",
            "100ë¶„ì˜ 5",
            "ì—° 5%"
        ]
        
        for keyword in keywords:
            print(f"\nğŸ” '{keyword}' ê²€ìƒ‰:")
            
            results = await self.search_laws(keyword, k=5)
            
            if results:
                print(f"  âœ… {len(results)}ê°œ ê²°ê³¼ ë°œê²¬")
                for i, result in enumerate(results, 1):
                    law_name = result.get('law_name', '')
                    distance = result.get('distance_score', 0)
                    
                    print(f"    [{i}] {law_name} (ê±°ë¦¬: {distance:.3f})")
                    
                    # ğŸ¯ ì£¼íƒì„ëŒ€ì°¨ ê´€ë ¨ ìƒì„¸ ë¶„ì„
                    if any(word in law_name for word in ["ì£¼íƒ", "ì„ëŒ€ì°¨", "ì„ëŒ€ë£Œ"]):
                        print(f"        ğŸ¯ ê´€ë ¨ ë²•ë ¹ ë°œê²¬!")
                        metadata = result.get('metadata', {})
                        print(f"        ğŸ“‹ ë©”íƒ€ë°ì´í„° í‚¤: {list(metadata.keys())}")
                        print(f"        ğŸ“„ ë‚´ìš©: {result.get('content', '')[:100]}...")
                        
                        # íŠ¹íˆ ì œ7ì¡° ê´€ë ¨ í™•ì¸
                        content = result.get('content', '')
                        if "ì œ7ì¡°" in content or "7ì¡°" in content:
                            print(f"        ğŸ¯ğŸ¯ ì œ7ì¡° ê´€ë ¨ ë‚´ìš© ë°œê²¬!")
            else:
                print(f"  âŒ ê²°ê³¼ ì—†ìŒ")
    
    async def _investigate_law_variations(self):
        """2ë‹¨ê³„: ë²•ë ¹ëª… ë³€í˜• ê²€ìƒ‰"""
        
        print("\n" + "ğŸ“‹ 2ë‹¨ê³„: ë²•ë ¹ëª… ë³€í˜• ê²€ìƒ‰")
        print("-" * 50)
        
        variations = [
            "ì£¼íƒ ì„ëŒ€ì°¨ ë³´í˜¸ë²•",        # ê³µë°± í¬í•¨
            "ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²•",          # í‘œì¤€
            "ì£¼íƒì„ëŒ€ì°¨ ë³´í˜¸ë²•",         # ë¶€ë¶„ ê³µë°±
            "ä½å®…è³ƒè²¸å€Ÿä¿è­·æ³•",          # í•œì
            "ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²•ë¥ ",        # ë²•ë¥ 
            "ì„ëŒ€ì°¨ë³´í˜¸ë²•",             # ë‹¨ì¶•
            "ì£¼íƒì„ëŒ€ì°¨ë²•",             # ë‹¨ì¶•2
            "ì£¼íƒì„ëŒ€ë³´í˜¸ë²•",           # ì˜¤íƒ€
        ]
        
        for variation in variations:
            print(f"\nğŸ” ë³€í˜• '{variation}' ê²€ìƒ‰:")
            
            # ì •í™• ê²€ìƒ‰ (ë”°ì˜´í‘œ)
            exact_results = await self.search_laws(f'"{variation}"', k=3)
            # ì¼ë°˜ ê²€ìƒ‰
            normal_results = await self.search_laws(variation, k=5)
            
            print(f"  ğŸ“ ì •í™• ê²€ìƒ‰: {len(exact_results)}ê°œ")
            print(f"  ğŸ“ ì¼ë°˜ ê²€ìƒ‰: {len(normal_results)}ê°œ")
            
            # ê²°ê³¼ ë¶„ì„
            all_results = exact_results + normal_results
            unique_results = self._deduplicate_results(all_results)
            
            if unique_results:
                for i, result in enumerate(unique_results[:3], 1):
                    law_name = result.get('law_name', '')
                    distance = result.get('distance_score', 0)
                    print(f"    [{i}] {law_name} (ê±°ë¦¬: {distance:.3f})")
                    
                    # ì •í™•í•œ ë§¤ì¹˜ì¸ì§€ í™•ì¸
                    if self._is_exact_match(variation, law_name):
                        print(f"        ğŸ¯ ì •í™•í•œ ë§¤ì¹˜ ë°œê²¬!")
                        print(f"        ğŸ“‹ ì „ì²´ ë©”íƒ€ë°ì´í„°: {result.get('metadata', {})}")
    
    async def _investigate_content_search(self):
        """3ë‹¨ê³„: ë‚´ìš© ê¸°ë°˜ ê²€ìƒ‰"""
        
        print("\n" + "ğŸ“‹ 3ë‹¨ê³„: ë‚´ìš© ê¸°ë°˜ ê²€ìƒ‰")
        print("-" * 50)
        
        # ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²• ì œ7ì¡° ì‹¤ì œ ë‚´ìš©ë“¤
        content_queries = [
            "ì„ëŒ€ë£Œë¥¼ ì¦ì•¡í•˜ë ¤ëŠ” ê²½ìš°",
            "100ë¶„ì˜ 5ë¥¼ ì´ˆê³¼í•˜ì§€ ëª»í•œë‹¤", 
            "ì„ëŒ€ë£Œì˜ 100ë¶„ì˜ 5",
            "ì—° 5í¼ì„¼íŠ¸ë¥¼ ì´ˆê³¼í•˜ì§€",
            "ì¦ì•¡ ë‹¹ì‹œì˜ ì„ëŒ€ë£Œ",
            "ì„ëŒ€ë£Œ ì¦ì•¡ ì œí•œ",
            "ì°¨ì„ ì¦ì•¡ ì œí•œ"
        ]
        
        for query in content_queries:
            print(f"\nğŸ” ë‚´ìš© ê²€ìƒ‰ '{query}':")
            
            results = await self.search_laws(query, k=5)
            
            if results:
                print(f"  âœ… {len(results)}ê°œ ê²°ê³¼")
                for i, result in enumerate(results, 1):
                    law_name = result.get('law_name', '')
                    distance = result.get('distance_score', 0)
                    content = result.get('content', '')
                    
                    print(f"    [{i}] {law_name} (ê±°ë¦¬: {distance:.3f})")
                    
                    # ë‚´ìš©ì—ì„œ í‚¤ì›Œë“œ í™•ì¸
                    if query in content:
                        print(f"        ğŸ¯ ë‚´ìš©ì—ì„œ í‚¤ì›Œë“œ ì •í™• ë°œê²¬!")
                        # í‚¤ì›Œë“œ ì£¼ë³€ í…ìŠ¤íŠ¸ ì¶”ì¶œ
                        start = max(0, content.find(query) - 50)
                        end = min(len(content), content.find(query) + len(query) + 50)
                        context = content[start:end]
                        print(f"        ğŸ“„ ë¬¸ë§¥: ...{context}...")
            else:
                print(f"  âŒ ê²°ê³¼ ì—†ìŒ")
    
    async def _investigate_metadata(self):
        """4ë‹¨ê³„: ë©”íƒ€ë°ì´í„° êµ¬ì¡° ë¶„ì„"""
        
        print("\n" + "ğŸ“‹ 4ë‹¨ê³„: ë©”íƒ€ë°ì´í„° êµ¬ì¡° ë¶„ì„")
        print("-" * 50)
        
        try:
            # ìƒ˜í”Œ ë°ì´í„°ë¡œ ë©”íƒ€ë°ì´í„° êµ¬ì¡° íŒŒì•…
            sample_results = await self.search_laws("ë²•", k=20)
            
            if sample_results:
                print(f"âœ… ìƒ˜í”Œ {len(sample_results)}ê°œë¡œ ë©”íƒ€ë°ì´í„° ë¶„ì„")
                
                # ëª¨ë“  ë©”íƒ€ë°ì´í„° í‚¤ ìˆ˜ì§‘
                all_keys = set()
                for result in sample_results:
                    metadata = result.get('metadata', {})
                    all_keys.update(metadata.keys())
                
                print(f"\nğŸ“‹ ë°œê²¬ëœ ë©”íƒ€ë°ì´í„° í•„ë“œë“¤:")
                for key in sorted(all_keys):
                    print(f"  - {key}")
                
                # ë²•ë ¹ëª… í•„ë“œ ìƒì„¸ ë¶„ì„
                print(f"\nğŸ“ ë²•ë ¹ëª… ê´€ë ¨ í•„ë“œ ë¶„ì„:")
                law_name_fields = [key for key in all_keys if any(word in key for word in ['ë²•ë ¹', 'law', 'ëª…', 'name'])]
                print(f"ë²•ë ¹ëª… í›„ë³´ í•„ë“œë“¤: {law_name_fields}")
                
                # ìƒ˜í”Œ 5ê°œ ìƒì„¸ ë¶„ì„
                print(f"\nğŸ“Š ìƒ˜í”Œ ë©”íƒ€ë°ì´í„° ìƒì„¸:")
                for i, result in enumerate(sample_results[:5], 1):
                    metadata = result.get('metadata', {})
                    print(f"  [{i}] í˜„ì¬ law_name: {result.get('law_name', 'N/A')}")
                    
                    for key, value in metadata.items():
                        if any(word in key for word in ['ë²•ë ¹', 'law', 'ëª…', 'name', 'ì œëª©']):
                            print(f"      {key}: {value}")
                    print()
            else:
                print("âŒ ìƒ˜í”Œ ê²°ê³¼ ì—†ìŒ")
                
        except Exception as e:
            print(f"âŒ ë©”íƒ€ë°ì´í„° ë¶„ì„ ì˜¤ë¥˜: {e}")
    
    async def _investigate_statistics(self):
        """5ë‹¨ê³„: í†µê³„ ë¶„ì„"""
        
        print("\n" + "ğŸ“‹ 5ë‹¨ê³„: ì „ì²´ í†µê³„ ë¶„ì„")
        print("-" * 50)
        
        housing_keywords = ["ì£¼íƒ", "ì„ëŒ€", "ì„ì°¨", "ì „ì„¸", "ì›”ì„¸", "ë³´ì¦ê¸ˆ"]
        
        for keyword in housing_keywords:
            print(f"\nğŸ“Š '{keyword}' ê´€ë ¨ ë²•ë ¹ í†µê³„:")
            
            try:
                results = await self.search_laws(keyword, k=30)  # ë§ì´ ê²€ìƒ‰
                print(f"  ì´ {len(results)}ê°œ ë°œê²¬")
                
                # ë²•ë ¹ë³„ ë¶„ë¥˜
                law_stats = {}
                for result in results:
                    law_name = result.get('law_name', '')
                    
                    # ê¸°ë³¸ ë²•ë ¹ëª… ì¶”ì¶œ
                    base_law = re.match(r'^([ê°€-í£]+ë²•)', law_name)
                    if base_law:
                        base_name = base_law.group(1)
                        if base_name in law_stats:
                            law_stats[base_name] += 1
                        else:
                            law_stats[base_name] = 1
                
                # ìƒìœ„ ë²•ë ¹ë“¤ ì¶œë ¥
                sorted_laws = sorted(law_stats.items(), key=lambda x: x[1], reverse=True)
                print(f"  ìƒìœ„ ë²•ë ¹ë“¤:")
                for law, count in sorted_laws[:8]:
                    print(f"    {law}: {count}ê°œ")
                    
                    # ğŸ¯ ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²• íŠ¹ë³„ ì²´í¬
                    if "ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²•" in law:
                        print(f"      ğŸ¯ğŸ¯ ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²• ë°œê²¬! {count}ê°œ ì¡°ë¬¸")
                        
                        # ê´€ë ¨ ì¡°ë¬¸ë“¤ ìƒì„¸ ë¶„ì„
                        housing_results = [r for r in results if "ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²•" in r.get('law_name', '')]
                        print(f"      ê´€ë ¨ ì¡°ë¬¸ë“¤:")
                        for hr in housing_results[:5]:
                            hn = hr.get('law_name', '')
                            print(f"        - {hn}")
                            
            except Exception as e:
                print(f"  âŒ '{keyword}' í†µê³„ ì˜¤ë¥˜: {e}")
    
    async def _generate_summary(self):
        """ì¡°ì‚¬ ê²°ê³¼ ìš”ì•½"""
        
        print("\nğŸ¯ í•µì‹¬ ë°œê²¬ì‚¬í•­:")
        
        # ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²• ì§ì ‘ ê²€ìƒ‰
        housing_law_results = await self.search_laws("ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²•", k=10)
        
        if housing_law_results:
            print(f"âœ… 'ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²•' ê²€ìƒ‰ ê²°ê³¼: {len(housing_law_results)}ê°œ")
            
            # ì œ7ì¡° ê´€ë ¨ ì°¾ê¸°
            article_7_found = False
            for result in housing_law_results:
                law_name = result.get('law_name', '')
                content = result.get('content', '')
                
                if "ì œ7ì¡°" in law_name or "ì œ7ì¡°" in content or "7ì¡°" in content:
                    print(f"ğŸ¯ ì œ7ì¡° ê´€ë ¨ ë°œê²¬: {law_name}")
                    print(f"   ê±°ë¦¬: {result.get('distance_score', 0):.3f}")
                    print(f"   ë©”íƒ€ë°ì´í„°: {result.get('metadata', {})}")
                    article_7_found = True
            
            if not article_7_found:
                print("âŒ ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²• ì œ7ì¡° ê´€ë ¨ ë‚´ìš© ì°¾ì„ ìˆ˜ ì—†ìŒ")
                
                print("\nğŸ’¡ ëŒ€ì•ˆ ê²€ìƒ‰ ì‹œë„:")
                alternative_queries = ["ì„ëŒ€ë£Œ ì¦ì•¡", "100ë¶„ì˜ 5", "ì—° 5í¼ì„¼íŠ¸"]
                for alt_query in alternative_queries:
                    alt_results = await self.search_laws(alt_query, k=3)
                    if alt_results:
                        print(f"  '{alt_query}' ê²€ìƒ‰ ê²°ê³¼:")
                        for ar in alt_results:
                            print(f"    - {ar.get('law_name', '')} (ê±°ë¦¬: {ar.get('distance_score', 0):.3f})")
        else:
            print("âŒ 'ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²•' ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
        
        print("\nğŸ“‹ ê¶Œì¥ í•´ê²° ë°©ì•ˆ:")
        print("1. DBì— ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²• ì œ7ì¡°ê°€ ì‹¤ì œë¡œ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸")
        print("2. ê²€ìƒ‰ë˜ì§€ ì•ŠëŠ”ë‹¤ë©´ ê²€ìƒ‰ ì•Œê³ ë¦¬ì¦˜ ê°œì„  í•„ìš”")
        print("3. ì•„ì˜ˆ ì—†ë‹¤ë©´ ë°©ì•ˆ1(ì •í™•í•œ ì •ë³´ ì œê³µ) ì ìš© ê¶Œì¥")
    
    def _deduplicate_results(self, results: List[Dict]) -> List[Dict]:
        """ê²°ê³¼ ì¤‘ë³µ ì œê±°"""
        seen = set()
        unique = []
        
        for result in results:
            law_name = result.get('law_name', '')
            if law_name not in seen:
                seen.add(law_name)
                unique.append(result)
        
        return unique
    
    def _is_exact_match(self, query: str, law_name: str) -> bool:
        """ì •í™•í•œ ë§¤ì¹˜ì¸ì§€ í™•ì¸"""
        query_clean = re.sub(r'[\s\-\.]', '', query.lower())
        law_clean = re.sub(r'[\s\-\.]', '', law_name.lower())
        
        return query_clean in law_clean or law_clean in query_clean

async def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²• DB ì¡°ì‚¬ ì‹œì‘")
    
    investigator = DatabaseInvestigator()
    
    if investigator.law_db is None:
        print("âŒ DB ì—°ê²° ì‹¤íŒ¨ - ì¡°ì‚¬ë¥¼ ì§„í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("ğŸ’¡ .env íŒŒì¼ê³¼ DB ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return
    
    await investigator.comprehensive_investigation()
    
    print("\nâœ… ì¡°ì‚¬ ì™„ë£Œ! ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ contract_service.py ê°œì„  ë°©ì•ˆì„ ì œì•ˆë°›ìœ¼ì„¸ìš”.")

if __name__ == "__main__":
    asyncio.run(main())